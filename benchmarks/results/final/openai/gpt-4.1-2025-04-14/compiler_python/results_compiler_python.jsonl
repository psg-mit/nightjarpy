{"file_name": "calendar_tool", "model": "openai/gpt-4.1-2025-04-14", "run": 0, "runtime": 4.655489683151245, "compile_time": 12.997005939483643, "hard_eval": {"test_0": false, "test_1": false, "test_2": true, "test_3": false}, "soft_eval": {}, "llm_judge_output": {"test_0": null, "test_1": null, "test_2": null, "test_3": null}, "token_count": {"input_tokens": 1405, "output_tokens": 277, "cached_token_reads": 0, "total_tokens": 1682}, "errors": {"test_0": null, "test_1": "SyntaxError: invalid syntax (<string>, line 1)", "test_2": null, "test_3": "SyntaxError: invalid syntax (<string>, line 1)"}, "n_tool_calls": 0}
{"file_name": "coffeeshop", "model": "openai/gpt-4.1-2025-04-14", "run": 0, "runtime": 2.5633556842803955, "compile_time": 9.603866338729858, "hard_eval": {"test_0_line_item_0_product_type_matches": false, "test_0_line_item_0_product_name_matches": false, "test_0_line_item_0_product_size_matches": false, "test_0_line_item_0_product_temperature_matches": false, "test_0_line_item_0_quantity_matches": false, "test_1_line_item_0_product_type_matches": false, "test_1_line_item_0_product_name_matches": false, "test_1_line_item_0_product_size_matches": false, "test_1_line_item_0_product_temperature_matches": false, "test_1_line_item_0_product_option_0_type_matches": false, "test_1_line_item_0_product_option_0_name_matches": false, "test_1_line_item_0_product_option_1_type_matches": false, "test_1_line_item_0_product_option_1_name_matches": false, "test_1_line_item_0_quantity_matches": false, "test_1_line_item_1_product_type_matches": false, "test_1_line_item_1_product_name_matches": false, "test_1_line_item_1_product_size_matches": false, "test_1_line_item_1_product_temperature_matches": false, "test_1_line_item_1_quantity_matches": false, "test_1_line_item_2_product_type_matches": false, "test_1_line_item_2_product_name_matches": false, "test_1_line_item_2_product_option_0_type_matches": false, "test_1_line_item_2_product_option_0_name_matches": false, "test_1_line_item_2_product_option_1_type_matches": false, "test_1_line_item_2_product_option_1_name_matches": false, "test_1_line_item_2_quantity_matches": false, "test_2": false, "test_3": false}, "soft_eval": {}, "llm_judge_output": {"test_0": null, "test_1": null, "test_2": null, "test_3": null}, "token_count": {"input_tokens": 3174, "output_tokens": 439, "cached_token_reads": 0, "total_tokens": 3613}, "errors": {"test_0": "BadRequestError: Error code: 400 - {'error': {'message': \"Invalid schema for response_format 'llm_cart_extraction_response': In context=('properties', 'items', 'items'), reference to component '#/$defs/LineItem' which was not found in the schema.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}", "test_1": "BadRequestError: Error code: 400 - {'error': {'message': \"Invalid schema for response_format 'llm_cart_extraction_response': In context=('properties', 'items', 'items'), reference to component '#/$defs/LineItem' which was not found in the schema.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}", "test_2": "BadRequestError: Error code: 400 - {'error': {'message': \"Invalid schema for response_format 'llm_cart_extraction_response': In context=('properties', 'items', 'items'), reference to component '#/$defs/LineItem' which was not found in the schema.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}", "test_3": "BadRequestError: Error code: 400 - {'error': {'message': \"Invalid schema for response_format 'llm_cart_extraction_response': In context=('properties', 'items', 'items'), reference to component '#/$defs/LineItem' which was not found in the schema.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}"}, "n_tool_calls": 0}
{"file_name": "enemy", "model": "openai/gpt-4.1-2025-04-14", "run": 0, "runtime": 9.632110595703125e-05, "compile_time": 3.407442331314087, "hard_eval": {"enemy_not_none": true, "enemy_name_str": true, "enemy_description_str": true, "enemy_health_int": true, "enemy_attack_power_int": true, "enemy_speak_method": true, "player1_attack_method": true, "enemy_before_health_gt_enemy_after_health": true, "speak_output_not_none": true}, "soft_eval": {}, "llm_judge_output": {"test_0": "=== Start Test ===\n\nplayer1: name=Knight Capy, health=100, attack_power=10\nenemy before attack: name=Goblin King, health=75, attack_power=8\nenemy after attack: name=Goblin King, health=65, attack_power=8\nspeak_output: You dare face me, mortal? Prepare to be crushed!\n\n=== End Test ===\n\n"}, "token_count": {"input_tokens": 1270, "output_tokens": 207, "cached_token_reads": 0, "total_tokens": 1477}, "errors": {}, "n_tool_calls": 0}
{"file_name": "feed_filtering", "model": "openai/gpt-4.1-2025-04-14", "run": 0, "runtime": 0.0003631114959716797, "compile_time": 1.5023517608642578, "hard_eval": {"test_technical_output_type": true, "test_technical_output_content_1": false, "test_technical_output_content_2": true, "test_technical_output_content_3": false, "test_technical_output_content_4": true, "test_technical_output_content_5": false, "test_spicy_output_type": true, "test_spicy_output_content_1": true, "test_spicy_output_content_2": false, "test_spicy_output_content_3": true, "test_spicy_output_content_4": false, "test_spicy_output_content_5": true}, "soft_eval": {}, "llm_judge_output": {"test_technical": "=== Start Test ===\n\nOriginal Posts: ['How is it that an LLM can know more than any single human but be unable to generate novel scientific discoveries?', 'AI is not useful for anything. I will die on this hill.', \"There's a serious question of what happens to LLM scaling when we run out of new high-quality data sources.\", \"Next-token prediction just doesn't make sense as a path to AGI. Why are we even funding this?\", \"Did you know a beaver's teeth never stop growing? They need to gnaw on wood constantly to keep them from growing too long.\"]\nFeed Preference: \n        I like content that discusses AI from a technical or philosophical perspective.\n        I am fine with content that is not about AI, so long as it is informative.\n        I do not like content that is deliberately inflammatory.\n    \nFeed Filtered Based on Preference: []\n=== End Test ===\n\n", "test_spicy": "=== Start Test ===\n\nOriginal Posts: ['How is it that an LLM can know more than any single human but be unable to generate novel scientific discoveries?', 'AI is not useful for anything. I will die on this hill.', \"There's a serious question of what happens to LLM scaling when we run out of new high-quality data sources.\", \"Next-token prediction just doesn't make sense as a path to AGI. Why are we even funding this?\", \"Did you know a beaver's teeth never stop growing? They need to gnaw on wood constantly to keep them from growing too long.\"]\nFeed Preference: \n        I don't like dry, technical content. I just want some hot takes and ragebait.\n        I'm also scared of beavers. Don't mention them.\n    \nFeed Filtered Based on Preference: []\n=== End Test ===\n\n"}, "token_count": {"input_tokens": 1053, "output_tokens": 26, "cached_token_reads": 0, "total_tokens": 1079}, "errors": {}, "n_tool_calls": 0}
{"file_name": "get_enemy", "model": "openai/gpt-4.1-2025-04-14", "run": 0, "runtime": 4.744529724121094e-05, "compile_time": 11.368024110794067, "hard_eval": {"enemy_not_predefined": false, "enemy_exists": false, "enemy_has_name": false, "enemy_name_is_str": false, "enemy_has_description": false, "enemy_description_is_str": false}, "soft_eval": {}, "llm_judge_output": {"test_0": null}, "token_count": {"input_tokens": 1118, "output_tokens": 73, "cached_token_reads": 0, "total_tokens": 1191}, "errors": {"test_0": "TypeError: 'NoneType' object is not callable"}, "n_tool_calls": 0}
{"file_name": "health_data", "model": "openai/gpt-4.1-2025-04-14", "run": 0, "runtime": 2.4472813606262207, "compile_time": 8.361182451248169, "hard_eval": {"health_data_type": true, "health_data_condition": true, "health_data_condition_name": true, "health_data_condition_start_date": true, "health_data_condition_status": true, "health_data_condition_end_date": true}, "soft_eval": {}, "llm_judge_output": {"test_0": "=== Start Test ===\n\n== Health Data ==\nMedication: []\nCondition: [Condition(name='Foot fracture', startDate=datetime.datetime(2001, 1, 1, 0, 0), status='resolved', endDate=datetime.datetime(2002, 1, 1, 0, 0))]\nOther: []\n\n== History ==\nsystem: Help the user enter their health data step by step.\nAsk specific questions to gather required and optional fields they have not already provided.\nStop asking if they don't know the answer\nAutomatically fix their spelling mistakes\nTheir health data may be complex: always record and return ALL of it.\nAlways return a response:\n- If you don't understand what they say, ask a question.\n- At least respond with an OK message.\nuser: I broke my foot\nI broke it in high school\n2001 january 1st\nThe foot took a year to be ok\n\nassistant: Your broken foot from high school in 2001 has been recorded as a resolved condition. If there is any more information or health data to add, let me know!\n\n=== End Test ===\n\n"}, "token_count": {"input_tokens": 1956, "output_tokens": 514, "cached_token_reads": 0, "total_tokens": 2470}, "errors": {}, "n_tool_calls": 0}
{"file_name": "mask_sensitive_information", "model": "openai/gpt-4.1-2025-04-14", "run": 0, "runtime": null, "compile_time": 9.407678842544556, "hard_eval": {}, "soft_eval": {}, "llm_judge_output": {}, "token_count": {"input_tokens": 1065, "output_tokens": 207, "cached_token_reads": 0, "total_tokens": 1272}, "errors": {"program_load": "str: Program load failed"}, "n_tool_calls": 0}
{"file_name": "proposer_verifier", "model": "openai/gpt-4.1-2025-04-14", "run": 0, "runtime": 5.105194568634033, "compile_time": 15.35358214378357, "hard_eval": {"proposal_is_string": true, "proposal_is_non_empty": true}, "soft_eval": {}, "llm_judge_output": {"test_0": "=== Start Test ===\n\nRiddle: 'I am the beginning of the end, and the end of time and space. I am essential to creation, and I surround every place. What am I?'\nFinal accepted proposal: 'The answer to the riddle is the letter \"e\".\n\nExplanation:\n- \"I am the beginning of the end\" \u2013 The word \"end\" starts with \"e\".\n- \"and the end of time and space\" \u2013 Both the words \"time\" and \"space\" end with \"e\".\n- \"I am essential to creation\" \u2013 The word \"creation\" contains \"e\".\n- \"and I surround every place\" \u2013 The word \"place\" is surrounded (starts and ends) with \"e\" when spoken of as 'e-place-e' (poetic license), but the main pattern is the frequent appearance of the letter 'e' in these words.'\n\n=== End Test ===\n\n"}, "token_count": {"input_tokens": 3573, "output_tokens": 484, "cached_token_reads": 1152, "total_tokens": 4057}, "errors": {}, "n_tool_calls": 0}
{"file_name": "sentiment", "model": "openai/gpt-4.1-2025-04-14", "run": 0, "runtime": 2.290571689605713, "compile_time": 10.812536239624023, "hard_eval": {"sentiment_is_string_1": true, "sentiment_is_positive": true, "sentiment_is_string_2": true, "sentiment_is_negative": true}, "soft_eval": {}, "llm_judge_output": {"test_0": "=== Start Test ===\n\nInput: 'I absolutely loved the new movie; it was a thrilling experience from start to finish!'\nExpected output: 'positive'\nOutput: 'positive'.\n\n=== End Test ===\n\n", "test_1": "=== Start Test ===\n\nInput: 'The service at the restaurant was disappointing and ruined our evening.'\nExpected output: 'negative'\nOutput: 'negative'.\n\n=== End Test ===\n\n"}, "token_count": {"input_tokens": 1029, "output_tokens": 180, "cached_token_reads": 0, "total_tokens": 1209}, "errors": {}, "n_tool_calls": 0}
{"file_name": "stores", "model": "openai/gpt-4.1-2025-04-14", "run": 0, "runtime": 1.5966284275054932, "compile_time": 5.626982927322388, "hard_eval": {"stores_type": true, "stores_count": true, "stores_instance_type_1": true, "stores_instance_type_2": true, "stores_instance_name_1": true, "stores_instance_city_1": true, "stores_instance_name_2": true, "stores_instance_city_2": false, "stores_instance_inventory_1": true, "stores_instance_inventory_2": true}, "soft_eval": {}, "llm_judge_output": {"test_0": null}, "token_count": {"input_tokens": 1202, "output_tokens": 466, "cached_token_reads": 0, "total_tokens": 1668}, "errors": {}, "n_tool_calls": 0}
{"file_name": "task_completion", "model": "openai/gpt-4.1-2025-04-14", "run": 0, "runtime": null, "compile_time": 1.1581861972808838, "hard_eval": {}, "soft_eval": {}, "llm_judge_output": {}, "token_count": {"input_tokens": 1079, "output_tokens": 34, "cached_token_reads": 0, "total_tokens": 1113}, "errors": {"program_load": "str: Program load failed"}, "n_tool_calls": 0}
{"file_name": "calendar_tool", "model": "openai/gpt-4.1-2025-04-14", "run": 1, "runtime": 0.00025200843811035156, "compile_time": 6.850428581237793, "hard_eval": {"test_0": false, "test_1": false, "test_2": false, "test_3": false}, "soft_eval": {}, "llm_judge_output": {"test_0": null, "test_1": null, "test_2": null, "test_3": null}, "token_count": {"input_tokens": 1405, "output_tokens": 830, "cached_token_reads": 0, "total_tokens": 2235}, "errors": {"test_0": null, "test_1": "NameError: name 'i' is not defined", "test_2": "NameError: name 'i' is not defined", "test_3": "NameError: name 'i' is not defined"}, "n_tool_calls": 0}
{"file_name": "calendar_tool", "model": "openai/gpt-4.1-2025-04-14", "run": 2, "runtime": 1.2908523082733154, "compile_time": 9.20456314086914, "hard_eval": {"test_0": false, "test_1": false, "test_2": false, "test_3": false}, "soft_eval": {}, "llm_judge_output": {"test_0": null, "test_1": null, "test_2": null, "test_3": null}, "token_count": {"input_tokens": 1405, "output_tokens": 721, "cached_token_reads": 1280, "total_tokens": 2126}, "errors": {"test_0": null, "test_1": "BadRequestError: Error code: 400 - {'error': {'message': \"Invalid schema for response_format 'calendar_request': In context=('properties', 'event'), 'required' is required to be supplied and to be an array including every key in properties. Missing 'participants'.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}", "test_2": "BadRequestError: Error code: 400 - {'error': {'message': \"Invalid schema for response_format 'calendar_request': In context=('properties', 'event'), 'required' is required to be supplied and to be an array including every key in properties. Missing 'participants'.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}", "test_3": "BadRequestError: Error code: 400 - {'error': {'message': \"Invalid schema for response_format 'calendar_request': In context=('properties', 'event'), 'required' is required to be supplied and to be an array including every key in properties. Missing 'participants'.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}"}, "n_tool_calls": 0}
{"file_name": "calendar_tool", "model": "openai/gpt-4.1-2025-04-14", "run": 3, "runtime": 2.1156668663024902, "compile_time": 10.339125394821167, "hard_eval": {"test_0": false, "test_1": false, "test_2": false, "test_3": false}, "soft_eval": {}, "llm_judge_output": {"test_0": null, "test_1": null, "test_2": null, "test_3": null}, "token_count": {"input_tokens": 1405, "output_tokens": 681, "cached_token_reads": 1280, "total_tokens": 2086}, "errors": {"test_0": null, "test_1": "BadRequestError: Error code: 400 - {'error': {'message': \"Invalid schema for response_format 'calendar_request_instructions': In context=(), 'required' is required to be supplied and to be an array including every key in properties. Missing 'event'.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}", "test_2": "BadRequestError: Error code: 400 - {'error': {'message': \"Invalid schema for response_format 'calendar_request_instructions': In context=(), 'required' is required to be supplied and to be an array including every key in properties. Missing 'event'.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}", "test_3": "BadRequestError: Error code: 400 - {'error': {'message': \"Invalid schema for response_format 'calendar_request_instructions': In context=(), 'required' is required to be supplied and to be an array including every key in properties. Missing 'event'.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}"}, "n_tool_calls": 0}
{"file_name": "calendar_tool", "model": "openai/gpt-4.1-2025-04-14", "run": 4, "runtime": null, "compile_time": 8.812988042831421, "hard_eval": {}, "soft_eval": {}, "llm_judge_output": {}, "token_count": {"input_tokens": 1405, "output_tokens": 886, "cached_token_reads": 1280, "total_tokens": 2291}, "errors": {"program_load": "str: Program load failed"}, "n_tool_calls": 0}
{"file_name": "coffeeshop", "model": "openai/gpt-4.1-2025-04-14", "run": 1, "runtime": 9.409196853637695, "compile_time": 9.364624261856079, "hard_eval": {"test_0_line_item_0_product_type_matches": true, "test_0_line_item_0_product_name_matches": true, "test_0_line_item_0_product_size_matches": true, "test_0_line_item_0_product_temperature_matches": true, "test_0_line_item_0_quantity_matches": true, "test_1_line_item_0_product_type_matches": true, "test_1_line_item_0_product_name_matches": false, "test_1_line_item_0_product_size_matches": false, "test_1_line_item_0_product_temperature_matches": true, "test_1_line_item_0_product_option_0_type_matches": true, "test_1_line_item_0_product_option_0_name_matches": true, "test_1_line_item_0_product_option_1_type_matches": false, "test_1_line_item_0_product_option_1_name_matches": false, "test_1_line_item_0_quantity_matches": true, "test_1_line_item_1_product_type_matches": false, "test_1_line_item_1_product_name_matches": false, "test_1_line_item_1_product_size_matches": false, "test_1_line_item_1_product_temperature_matches": true, "test_1_line_item_1_quantity_matches": true, "test_1_line_item_2_product_type_matches": false, "test_1_line_item_2_product_name_matches": false, "test_1_line_item_2_product_option_0_type_matches": false, "test_1_line_item_2_product_option_0_name_matches": false, "test_1_line_item_2_product_option_1_type_matches": false, "test_1_line_item_2_product_option_1_name_matches": false, "test_1_line_item_2_quantity_matches": true, "test_1_line_item_3_product_type_matches": false, "test_1_line_item_3_product_name_matches": false, "test_1_line_item_3_product_option_0_type_matches": false, "test_1_line_item_3_product_option_0_name_matches": false, "test_1_line_item_3_product_option_1_type_matches": false, "test_1_line_item_3_product_option_1_name_matches": false, "test_1_line_item_3_quantity_matches": false, "test_2": true, "test_3": true}, "soft_eval": {}, "llm_judge_output": {"test_0": "=== Start Test ===\nInput: i'd like a latte that's it\nExpected Output: items=[LineItem(product=LatteDrink(name='latte', temperature=None, size='grande', options=[]), quantity=1)]\nActual Output: items=[LineItem(product=LatteDrink(name='latte', temperature=None, size='grande', options=[]), quantity=1)]\n=== End Test ===\n\n", "test_1": "=== Start Test ===\nInput: i'd like a tall decaf latte iced a grande cappuccino double espresso and a warmed poppyseed muffin sliced in half\nExpected Output: items=[LineItem(product=LatteDrink(name='cappuccino', temperature='iced', size='grande', options=[Caffeine(name='decaf'), LattePreparation(name='dry')]), quantity=1), LineItem(product=EspressoDrink(name='espresso', temperature=None, size=None, options=[]), quantity=1), LineItem(product=BakeryProduct(name='lemon poppyseed muffin', options=[BakeryPreparation(name='warmed'), BakeryPreparation(name='cut in half')]), quantity=1)]\nActual Output: items=[LineItem(product=LatteDrink(name='latte', temperature='iced', size='tall', options=[Caffeine(name='decaf')]), quantity=1), LineItem(product=LatteDrink(name='cappuccino', temperature=None, size='grande', options=[]), quantity=1), LineItem(product=EspressoDrink(name='espresso', temperature=None, size='doppio', options=[]), quantity=1), LineItem(product=BakeryProduct(name='lemon poppyseed muffin', options=[BakeryPreparation(name='warmed'), BakeryPreparation(name='cut in half')]), quantity=1)]\n=== End Test ===\n\n", "test_2": "=== Start Test ===\nInput: two lawnmowers, a grande latte and a tall tree\nExpected Output: ['lawnmowers', 'tree']\nActual Output: I did not understand the following: two lawnmowers, a tall tree\n=== End Test ===\n\n", "test_3": "=== Start Test ===\nInput: un petit cafe\nExpected Output: ['cafe']\nActual Output: I did not understand the following: un petit cafe\n=== End Test ===\n\n"}, "token_count": {"input_tokens": 3174, "output_tokens": 356, "cached_token_reads": 0, "total_tokens": 3530}, "errors": {"test_0": null, "test_1": null, "test_2": null, "test_3": null}, "n_tool_calls": 0}
{"file_name": "coffeeshop", "model": "openai/gpt-4.1-2025-04-14", "run": 2, "runtime": 2.243997573852539, "compile_time": 8.531656265258789, "hard_eval": {"test_0_line_item_0_product_type_matches": false, "test_0_line_item_0_product_name_matches": false, "test_0_line_item_0_product_size_matches": false, "test_0_line_item_0_product_temperature_matches": false, "test_0_line_item_0_quantity_matches": false, "test_1_line_item_0_product_type_matches": false, "test_1_line_item_0_product_name_matches": false, "test_1_line_item_0_product_size_matches": false, "test_1_line_item_0_product_temperature_matches": false, "test_1_line_item_0_product_option_0_type_matches": false, "test_1_line_item_0_product_option_0_name_matches": false, "test_1_line_item_0_product_option_1_type_matches": false, "test_1_line_item_0_product_option_1_name_matches": false, "test_1_line_item_0_quantity_matches": false, "test_1_line_item_1_product_type_matches": false, "test_1_line_item_1_product_name_matches": false, "test_1_line_item_1_product_size_matches": false, "test_1_line_item_1_product_temperature_matches": false, "test_1_line_item_1_quantity_matches": false, "test_1_line_item_2_product_type_matches": false, "test_1_line_item_2_product_name_matches": false, "test_1_line_item_2_product_option_0_type_matches": false, "test_1_line_item_2_product_option_0_name_matches": false, "test_1_line_item_2_product_option_1_type_matches": false, "test_1_line_item_2_product_option_1_name_matches": false, "test_1_line_item_2_quantity_matches": false, "test_2": false, "test_3": false}, "soft_eval": {}, "llm_judge_output": {"test_0": null, "test_1": null, "test_2": null, "test_3": null}, "token_count": {"input_tokens": 3174, "output_tokens": 451, "cached_token_reads": 3072, "total_tokens": 3625}, "errors": {"test_0": "BadRequestError: Error code: 400 - {'error': {'message': \"Invalid schema for response_format 'cart_extraction': In context=('properties', 'items', 'items'), 'additionalProperties' is required to be supplied and to be false.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}", "test_1": "BadRequestError: Error code: 400 - {'error': {'message': \"Invalid schema for response_format 'cart_extraction': In context=('properties', 'items', 'items'), 'additionalProperties' is required to be supplied and to be false.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}", "test_2": "BadRequestError: Error code: 400 - {'error': {'message': \"Invalid schema for response_format 'cart_extraction': In context=('properties', 'items', 'items'), 'additionalProperties' is required to be supplied and to be false.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}", "test_3": "BadRequestError: Error code: 400 - {'error': {'message': \"Invalid schema for response_format 'cart_extraction': In context=('properties', 'items', 'items'), 'additionalProperties' is required to be supplied and to be false.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}"}, "n_tool_calls": 0}
{"file_name": "coffeeshop", "model": "openai/gpt-4.1-2025-04-14", "run": 3, "runtime": 2.1730597019195557, "compile_time": 10.650700330734253, "hard_eval": {"test_0_line_item_0_product_type_matches": false, "test_0_line_item_0_product_name_matches": false, "test_0_line_item_0_product_size_matches": false, "test_0_line_item_0_product_temperature_matches": false, "test_0_line_item_0_quantity_matches": false, "test_1_line_item_0_product_type_matches": false, "test_1_line_item_0_product_name_matches": false, "test_1_line_item_0_product_size_matches": false, "test_1_line_item_0_product_temperature_matches": false, "test_1_line_item_0_product_option_0_type_matches": false, "test_1_line_item_0_product_option_0_name_matches": false, "test_1_line_item_0_product_option_1_type_matches": false, "test_1_line_item_0_product_option_1_name_matches": false, "test_1_line_item_0_quantity_matches": false, "test_1_line_item_1_product_type_matches": false, "test_1_line_item_1_product_name_matches": false, "test_1_line_item_1_product_size_matches": false, "test_1_line_item_1_product_temperature_matches": false, "test_1_line_item_1_quantity_matches": false, "test_1_line_item_2_product_type_matches": false, "test_1_line_item_2_product_name_matches": false, "test_1_line_item_2_product_option_0_type_matches": false, "test_1_line_item_2_product_option_0_name_matches": false, "test_1_line_item_2_product_option_1_type_matches": false, "test_1_line_item_2_product_option_1_name_matches": false, "test_1_line_item_2_quantity_matches": false, "test_2": false, "test_3": false}, "soft_eval": {}, "llm_judge_output": {"test_0": null, "test_1": null, "test_2": null, "test_3": null}, "token_count": {"input_tokens": 3174, "output_tokens": 591, "cached_token_reads": 3072, "total_tokens": 3765}, "errors": {"test_0": "BadRequestError: Error code: 400 - {'error': {'message': \"Invalid type for 'messages[0].content[0]': expected an object, but got a string instead.\", 'type': 'invalid_request_error', 'param': 'messages[0].content[0]', 'code': 'invalid_type'}}", "test_1": "BadRequestError: Error code: 400 - {'error': {'message': \"Invalid type for 'messages[0].content[0]': expected an object, but got a string instead.\", 'type': 'invalid_request_error', 'param': 'messages[0].content[0]', 'code': 'invalid_type'}}", "test_2": "BadRequestError: Error code: 400 - {'error': {'message': \"Invalid type for 'messages[0].content[0]': expected an object, but got a string instead.\", 'type': 'invalid_request_error', 'param': 'messages[0].content[0]', 'code': 'invalid_type'}}", "test_3": "BadRequestError: Error code: 400 - {'error': {'message': \"Invalid type for 'messages[0].content[0]': expected an object, but got a string instead.\", 'type': 'invalid_request_error', 'param': 'messages[0].content[0]', 'code': 'invalid_type'}}"}, "n_tool_calls": 0}
{"file_name": "coffeeshop", "model": "openai/gpt-4.1-2025-04-14", "run": 4, "runtime": 2.127169609069824, "compile_time": 8.401142835617065, "hard_eval": {"test_0_line_item_0_product_type_matches": false, "test_0_line_item_0_product_name_matches": false, "test_0_line_item_0_product_size_matches": false, "test_0_line_item_0_product_temperature_matches": false, "test_0_line_item_0_quantity_matches": false, "test_1_line_item_0_product_type_matches": false, "test_1_line_item_0_product_name_matches": false, "test_1_line_item_0_product_size_matches": false, "test_1_line_item_0_product_temperature_matches": false, "test_1_line_item_0_product_option_0_type_matches": false, "test_1_line_item_0_product_option_0_name_matches": false, "test_1_line_item_0_product_option_1_type_matches": false, "test_1_line_item_0_product_option_1_name_matches": false, "test_1_line_item_0_quantity_matches": false, "test_1_line_item_1_product_type_matches": false, "test_1_line_item_1_product_name_matches": false, "test_1_line_item_1_product_size_matches": false, "test_1_line_item_1_product_temperature_matches": false, "test_1_line_item_1_quantity_matches": false, "test_1_line_item_2_product_type_matches": false, "test_1_line_item_2_product_name_matches": false, "test_1_line_item_2_product_option_0_type_matches": false, "test_1_line_item_2_product_option_0_name_matches": false, "test_1_line_item_2_product_option_1_type_matches": false, "test_1_line_item_2_product_option_1_name_matches": false, "test_1_line_item_2_quantity_matches": false, "test_2": false, "test_3": false}, "soft_eval": {}, "llm_judge_output": {"test_0": null, "test_1": null, "test_2": null, "test_3": null}, "token_count": {"input_tokens": 3174, "output_tokens": 604, "cached_token_reads": 0, "total_tokens": 3778}, "errors": {"test_0": "BadRequestError: Error code: 400 - {'error': {'message': \"Invalid schema for response_format 'cart_extraction_response': In context=('properties', 'cart'), schema must have a 'type' key.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}", "test_1": "BadRequestError: Error code: 400 - {'error': {'message': \"Invalid schema for response_format 'cart_extraction_response': In context=('properties', 'cart'), schema must have a 'type' key.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}", "test_2": "BadRequestError: Error code: 400 - {'error': {'message': \"Invalid schema for response_format 'cart_extraction_response': In context=('properties', 'cart'), schema must have a 'type' key.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}", "test_3": "BadRequestError: Error code: 400 - {'error': {'message': \"Invalid schema for response_format 'cart_extraction_response': In context=('properties', 'cart'), schema must have a 'type' key.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}"}, "n_tool_calls": 0}
{"file_name": "enemy", "model": "openai/gpt-4.1-2025-04-14", "run": 1, "runtime": 8.368492126464844e-05, "compile_time": 2.500901699066162, "hard_eval": {"enemy_not_none": true, "enemy_name_str": true, "enemy_description_str": true, "enemy_health_int": true, "enemy_attack_power_int": true, "enemy_speak_method": true, "player1_attack_method": true, "enemy_before_health_gt_enemy_after_health": true, "speak_output_not_none": true}, "soft_eval": {}, "llm_judge_output": {"test_0": "=== Start Test ===\n\nplayer1: name=Knight Capy, health=100, attack_power=10\nenemy before attack: name=Goblin Shaman, health=60, attack_power=8\nenemy after attack: name=Goblin Shaman, health=50, attack_power=8\nspeak_output: Goblin Shaman hisses: You'll never beat me, foolish knight!\n\n=== End Test ===\n\n"}, "token_count": {"input_tokens": 1270, "output_tokens": 187, "cached_token_reads": 0, "total_tokens": 1457}, "errors": {}, "n_tool_calls": 0}
{"file_name": "enemy", "model": "openai/gpt-4.1-2025-04-14", "run": 2, "runtime": 5.3882598876953125e-05, "compile_time": 2.8203065395355225, "hard_eval": {"enemy_not_none": true, "enemy_name_str": true, "enemy_description_str": true, "enemy_health_int": true, "enemy_attack_power_int": true, "enemy_speak_method": true, "player1_attack_method": true, "enemy_before_health_gt_enemy_after_health": true, "speak_output_not_none": true}, "soft_eval": {}, "llm_judge_output": {"test_0": "=== Start Test ===\n\nplayer1: name=Knight Capy, health=100, attack_power=10\nenemy before attack: name=Goblin King, health=80, attack_power=12\nenemy after attack: name=Goblin King, health=70, attack_power=12\nspeak_output: You shall not pass, puny knight!\n\n=== End Test ===\n\n"}, "token_count": {"input_tokens": 1270, "output_tokens": 180, "cached_token_reads": 1152, "total_tokens": 1450}, "errors": {}, "n_tool_calls": 0}
{"file_name": "enemy", "model": "openai/gpt-4.1-2025-04-14", "run": 3, "runtime": 5.745887756347656e-05, "compile_time": 2.8082046508789062, "hard_eval": {"enemy_not_none": true, "enemy_name_str": true, "enemy_description_str": true, "enemy_health_int": true, "enemy_attack_power_int": true, "enemy_speak_method": true, "player1_attack_method": true, "enemy_before_health_gt_enemy_after_health": true, "speak_output_not_none": true}, "soft_eval": {}, "llm_judge_output": {"test_0": "=== Start Test ===\n\nplayer1: name=Knight Capy, health=100, attack_power=10\nenemy before attack: name=Goblin King, health=60, attack_power=8\nenemy after attack: name=Goblin King, health=50, attack_power=8\nspeak_output: You dare challenge me, foolish human?\n\n=== End Test ===\n\n"}, "token_count": {"input_tokens": 1270, "output_tokens": 161, "cached_token_reads": 1152, "total_tokens": 1431}, "errors": {}, "n_tool_calls": 0}
{"file_name": "enemy", "model": "openai/gpt-4.1-2025-04-14", "run": 4, "runtime": 0.00013518333435058594, "compile_time": 2.7693731784820557, "hard_eval": {"enemy_not_none": true, "enemy_name_str": true, "enemy_description_str": true, "enemy_health_int": true, "enemy_attack_power_int": true, "enemy_speak_method": true, "player1_attack_method": true, "enemy_before_health_gt_enemy_after_health": true, "speak_output_not_none": true}, "soft_eval": {}, "llm_judge_output": {"test_0": "=== Start Test ===\n\nplayer1: name=Knight Capy, health=100, attack_power=10\nenemy before attack: name=Goblin Sorcerer, health=80, attack_power=12\nenemy after attack: name=Goblin Sorcerer, health=70, attack_power=12\nspeak_output: Goblin Sorcerer hisses: 'You'll never leave these caves alive!'\n\n=== End Test ===\n\n"}, "token_count": {"input_tokens": 1270, "output_tokens": 195, "cached_token_reads": 1152, "total_tokens": 1465}, "errors": {}, "n_tool_calls": 0}
{"file_name": "feed_filtering", "model": "openai/gpt-4.1-2025-04-14", "run": 1, "runtime": 5.841255187988281e-05, "compile_time": 1.46665358543396, "hard_eval": {"test_technical_output_type": true, "test_technical_output_content_1": false, "test_technical_output_content_2": true, "test_technical_output_content_3": false, "test_technical_output_content_4": true, "test_technical_output_content_5": false, "test_spicy_output_type": true, "test_spicy_output_content_1": true, "test_spicy_output_content_2": false, "test_spicy_output_content_3": true, "test_spicy_output_content_4": false, "test_spicy_output_content_5": true}, "soft_eval": {}, "llm_judge_output": {"test_technical": "=== Start Test ===\n\nOriginal Posts: ['How is it that an LLM can know more than any single human but be unable to generate novel scientific discoveries?', 'AI is not useful for anything. I will die on this hill.', \"There's a serious question of what happens to LLM scaling when we run out of new high-quality data sources.\", \"Next-token prediction just doesn't make sense as a path to AGI. Why are we even funding this?\", \"Did you know a beaver's teeth never stop growing? They need to gnaw on wood constantly to keep them from growing too long.\"]\nFeed Preference: \n        I like content that discusses AI from a technical or philosophical perspective.\n        I am fine with content that is not about AI, so long as it is informative.\n        I do not like content that is deliberately inflammatory.\n    \nFeed Filtered Based on Preference: []\n=== End Test ===\n\n", "test_spicy": "=== Start Test ===\n\nOriginal Posts: ['How is it that an LLM can know more than any single human but be unable to generate novel scientific discoveries?', 'AI is not useful for anything. I will die on this hill.', \"There's a serious question of what happens to LLM scaling when we run out of new high-quality data sources.\", \"Next-token prediction just doesn't make sense as a path to AGI. Why are we even funding this?\", \"Did you know a beaver's teeth never stop growing? They need to gnaw on wood constantly to keep them from growing too long.\"]\nFeed Preference: \n        I don't like dry, technical content. I just want some hot takes and ragebait.\n        I'm also scared of beavers. Don't mention them.\n    \nFeed Filtered Based on Preference: []\n=== End Test ===\n\n"}, "token_count": {"input_tokens": 1053, "output_tokens": 93, "cached_token_reads": 0, "total_tokens": 1146}, "errors": {}, "n_tool_calls": 0}
{"file_name": "feed_filtering", "model": "openai/gpt-4.1-2025-04-14", "run": 2, "runtime": 8.368492126464844e-05, "compile_time": 1.3520729541778564, "hard_eval": {"test_technical_output_type": true, "test_technical_output_content_1": false, "test_technical_output_content_2": true, "test_technical_output_content_3": false, "test_technical_output_content_4": true, "test_technical_output_content_5": false, "test_spicy_output_type": true, "test_spicy_output_content_1": true, "test_spicy_output_content_2": false, "test_spicy_output_content_3": true, "test_spicy_output_content_4": false, "test_spicy_output_content_5": true}, "soft_eval": {}, "llm_judge_output": {"test_technical": "=== Start Test ===\n\nOriginal Posts: ['How is it that an LLM can know more than any single human but be unable to generate novel scientific discoveries?', 'AI is not useful for anything. I will die on this hill.', \"There's a serious question of what happens to LLM scaling when we run out of new high-quality data sources.\", \"Next-token prediction just doesn't make sense as a path to AGI. Why are we even funding this?\", \"Did you know a beaver's teeth never stop growing? They need to gnaw on wood constantly to keep them from growing too long.\"]\nFeed Preference: \n        I like content that discusses AI from a technical or philosophical perspective.\n        I am fine with content that is not about AI, so long as it is informative.\n        I do not like content that is deliberately inflammatory.\n    \nFeed Filtered Based on Preference: []\n=== End Test ===\n\n", "test_spicy": "=== Start Test ===\n\nOriginal Posts: ['How is it that an LLM can know more than any single human but be unable to generate novel scientific discoveries?', 'AI is not useful for anything. I will die on this hill.', \"There's a serious question of what happens to LLM scaling when we run out of new high-quality data sources.\", \"Next-token prediction just doesn't make sense as a path to AGI. Why are we even funding this?\", \"Did you know a beaver's teeth never stop growing? They need to gnaw on wood constantly to keep them from growing too long.\"]\nFeed Preference: \n        I don't like dry, technical content. I just want some hot takes and ragebait.\n        I'm also scared of beavers. Don't mention them.\n    \nFeed Filtered Based on Preference: []\n=== End Test ===\n\n"}, "token_count": {"input_tokens": 1053, "output_tokens": 26, "cached_token_reads": 0, "total_tokens": 1079}, "errors": {}, "n_tool_calls": 0}
{"file_name": "feed_filtering", "model": "openai/gpt-4.1-2025-04-14", "run": 3, "runtime": 8.344650268554688e-05, "compile_time": 1.1444776058197021, "hard_eval": {"test_technical_output_type": true, "test_technical_output_content_1": false, "test_technical_output_content_2": true, "test_technical_output_content_3": false, "test_technical_output_content_4": true, "test_technical_output_content_5": false, "test_spicy_output_type": true, "test_spicy_output_content_1": true, "test_spicy_output_content_2": false, "test_spicy_output_content_3": true, "test_spicy_output_content_4": false, "test_spicy_output_content_5": true}, "soft_eval": {}, "llm_judge_output": {"test_technical": "=== Start Test ===\n\nOriginal Posts: ['How is it that an LLM can know more than any single human but be unable to generate novel scientific discoveries?', 'AI is not useful for anything. I will die on this hill.', \"There's a serious question of what happens to LLM scaling when we run out of new high-quality data sources.\", \"Next-token prediction just doesn't make sense as a path to AGI. Why are we even funding this?\", \"Did you know a beaver's teeth never stop growing? They need to gnaw on wood constantly to keep them from growing too long.\"]\nFeed Preference: \n        I like content that discusses AI from a technical or philosophical perspective.\n        I am fine with content that is not about AI, so long as it is informative.\n        I do not like content that is deliberately inflammatory.\n    \nFeed Filtered Based on Preference: []\n=== End Test ===\n\n", "test_spicy": "=== Start Test ===\n\nOriginal Posts: ['How is it that an LLM can know more than any single human but be unable to generate novel scientific discoveries?', 'AI is not useful for anything. I will die on this hill.', \"There's a serious question of what happens to LLM scaling when we run out of new high-quality data sources.\", \"Next-token prediction just doesn't make sense as a path to AGI. Why are we even funding this?\", \"Did you know a beaver's teeth never stop growing? They need to gnaw on wood constantly to keep them from growing too long.\"]\nFeed Preference: \n        I don't like dry, technical content. I just want some hot takes and ragebait.\n        I'm also scared of beavers. Don't mention them.\n    \nFeed Filtered Based on Preference: []\n=== End Test ===\n\n"}, "token_count": {"input_tokens": 1053, "output_tokens": 46, "cached_token_reads": 1024, "total_tokens": 1099}, "errors": {}, "n_tool_calls": 0}
{"file_name": "feed_filtering", "model": "openai/gpt-4.1-2025-04-14", "run": 4, "runtime": 6.818771362304688e-05, "compile_time": 1.1593306064605713, "hard_eval": {"test_technical_output_type": true, "test_technical_output_content_1": false, "test_technical_output_content_2": true, "test_technical_output_content_3": false, "test_technical_output_content_4": true, "test_technical_output_content_5": false, "test_spicy_output_type": true, "test_spicy_output_content_1": true, "test_spicy_output_content_2": false, "test_spicy_output_content_3": true, "test_spicy_output_content_4": false, "test_spicy_output_content_5": true}, "soft_eval": {}, "llm_judge_output": {"test_technical": "=== Start Test ===\n\nOriginal Posts: ['How is it that an LLM can know more than any single human but be unable to generate novel scientific discoveries?', 'AI is not useful for anything. I will die on this hill.', \"There's a serious question of what happens to LLM scaling when we run out of new high-quality data sources.\", \"Next-token prediction just doesn't make sense as a path to AGI. Why are we even funding this?\", \"Did you know a beaver's teeth never stop growing? They need to gnaw on wood constantly to keep them from growing too long.\"]\nFeed Preference: \n        I like content that discusses AI from a technical or philosophical perspective.\n        I am fine with content that is not about AI, so long as it is informative.\n        I do not like content that is deliberately inflammatory.\n    \nFeed Filtered Based on Preference: []\n=== End Test ===\n\n", "test_spicy": "=== Start Test ===\n\nOriginal Posts: ['How is it that an LLM can know more than any single human but be unable to generate novel scientific discoveries?', 'AI is not useful for anything. I will die on this hill.', \"There's a serious question of what happens to LLM scaling when we run out of new high-quality data sources.\", \"Next-token prediction just doesn't make sense as a path to AGI. Why are we even funding this?\", \"Did you know a beaver's teeth never stop growing? They need to gnaw on wood constantly to keep them from growing too long.\"]\nFeed Preference: \n        I don't like dry, technical content. I just want some hot takes and ragebait.\n        I'm also scared of beavers. Don't mention them.\n    \nFeed Filtered Based on Preference: []\n=== End Test ===\n\n"}, "token_count": {"input_tokens": 1053, "output_tokens": 26, "cached_token_reads": 1024, "total_tokens": 1079}, "errors": {}, "n_tool_calls": 0}
{"file_name": "get_enemy", "model": "openai/gpt-4.1-2025-04-14", "run": 1, "runtime": 6.771087646484375e-05, "compile_time": 1.9732251167297363, "hard_eval": {"enemy_not_predefined": true, "enemy_exists": true, "enemy_has_name": false, "enemy_name_is_str": false, "enemy_has_description": false, "enemy_description_is_str": false}, "soft_eval": {}, "llm_judge_output": {"test_0": null}, "token_count": {"input_tokens": 1118, "output_tokens": 81, "cached_token_reads": 0, "total_tokens": 1199}, "errors": {"test_0": "AttributeError: 'dict' object has no attribute 'name'"}, "n_tool_calls": 0}
{"file_name": "get_enemy", "model": "openai/gpt-4.1-2025-04-14", "run": 2, "runtime": 3.147125244140625e-05, "compile_time": 1.6804792881011963, "hard_eval": {"enemy_not_predefined": true, "enemy_exists": true, "enemy_has_name": false, "enemy_name_is_str": false, "enemy_has_description": false, "enemy_description_is_str": false}, "soft_eval": {}, "llm_judge_output": {"test_0": null}, "token_count": {"input_tokens": 1118, "output_tokens": 76, "cached_token_reads": 1024, "total_tokens": 1194}, "errors": {"test_0": "AttributeError: 'dict' object has no attribute 'name'"}, "n_tool_calls": 0}
{"file_name": "get_enemy", "model": "openai/gpt-4.1-2025-04-14", "run": 3, "runtime": 4.124641418457031e-05, "compile_time": 2.125070810317993, "hard_eval": {"enemy_not_predefined": false, "enemy_exists": false, "enemy_has_name": false, "enemy_name_is_str": false, "enemy_has_description": false, "enemy_description_is_str": false}, "soft_eval": {}, "llm_judge_output": {"test_0": null}, "token_count": {"input_tokens": 1118, "output_tokens": 80, "cached_token_reads": 1024, "total_tokens": 1198}, "errors": {"test_0": "TypeError: 'NoneType' object is not callable"}, "n_tool_calls": 0}
{"file_name": "get_enemy", "model": "openai/gpt-4.1-2025-04-14", "run": 4, "runtime": 4.124641418457031e-05, "compile_time": 1.552525520324707, "hard_eval": {"enemy_not_predefined": true, "enemy_exists": true, "enemy_has_name": false, "enemy_name_is_str": false, "enemy_has_description": false, "enemy_description_is_str": false}, "soft_eval": {}, "llm_judge_output": {"test_0": null}, "token_count": {"input_tokens": 1118, "output_tokens": 54, "cached_token_reads": 1024, "total_tokens": 1172}, "errors": {"test_0": "AttributeError: 'dict' object has no attribute 'name'"}, "n_tool_calls": 0}
{"file_name": "health_data", "model": "openai/gpt-4.1-2025-04-14", "run": 1, "runtime": 0.5666837692260742, "compile_time": 16.75846767425537, "hard_eval": {"health_data_type": false, "health_data_condition": false, "health_data_condition_name": false, "health_data_condition_start_date": false, "health_data_condition_status": false, "health_data_condition_end_date": false}, "soft_eval": {}, "llm_judge_output": {"test_0": null}, "token_count": {"input_tokens": 1956, "output_tokens": 450, "cached_token_reads": 0, "total_tokens": 2406}, "errors": {"test_0": "BadRequestError: Error code: 400 - {'error': {'message': \"Invalid schema for response_format 'healthdata_response': In context=('properties', 'health_data'), 'additionalProperties' is required to be supplied and to be false.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}"}, "n_tool_calls": 0}
{"file_name": "health_data", "model": "openai/gpt-4.1-2025-04-14", "run": 2, "runtime": 0.4073796272277832, "compile_time": 10.589724063873291, "hard_eval": {"health_data_type": false, "health_data_condition": false, "health_data_condition_name": false, "health_data_condition_start_date": false, "health_data_condition_status": false, "health_data_condition_end_date": false}, "soft_eval": {}, "llm_judge_output": {"test_0": null}, "token_count": {"input_tokens": 1956, "output_tokens": 643, "cached_token_reads": 1920, "total_tokens": 2599}, "errors": {"test_0": "BadRequestError: Error code: 400 - {'error': {'message': \"Invalid schema for response_format 'health_session_response': In context=('properties', 'health_data_json', 'anyOf', '0', 'properties', 'medication', 'items'), reference to component '#/$defs/Medication' which was not found in the schema.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}"}, "n_tool_calls": 0}
{"file_name": "health_data", "model": "openai/gpt-4.1-2025-04-14", "run": 3, "runtime": 2.07170033454895, "compile_time": 8.303470373153687, "hard_eval": {"health_data_type": true, "health_data_condition": true, "health_data_condition_name": true, "health_data_condition_start_date": true, "health_data_condition_status": true, "health_data_condition_end_date": true}, "soft_eval": {}, "llm_judge_output": {"test_0": "=== Start Test ===\n\n== Health Data ==\nMedication: []\nCondition: [Condition(name='broken foot', startDate=datetime.datetime(2001, 1, 1, 0, 0), status='resolved', endDate=datetime.datetime(2002, 1, 1, 0, 0))]\nOther: []\n\n== History ==\nsystem: Help the user enter their health data step by step.\nAsk specific questions to gather required and optional fields they have not already provided.\nStop asking if they don't know the answer\nAutomatically fix their spelling mistakes\nTheir health data may be complex: always record and return ALL of it.\nAlways return a response:\n- If you don't understand what they say, ask a question.\n- At least respond with an OK message.\nuser: I broke my foot\nI broke it in high school\n2001 january 1st\nThe foot took a year to be ok\n\nassistant: I've recorded your broken foot, which occurred on January 1, 2001 during high school and resolved after about a year. Do you have any other medical conditions, medications you take, or other health details to add?\n\n=== End Test ===\n\n"}, "token_count": {"input_tokens": 1956, "output_tokens": 513, "cached_token_reads": 1920, "total_tokens": 2469}, "errors": {}, "n_tool_calls": 0}
{"file_name": "health_data", "model": "openai/gpt-4.1-2025-04-14", "run": 4, "runtime": 1.8712666034698486, "compile_time": 12.621472597122192, "hard_eval": {"health_data_type": true, "health_data_condition": true, "health_data_condition_name": true, "health_data_condition_start_date": true, "health_data_condition_status": true, "health_data_condition_end_date": true}, "soft_eval": {}, "llm_judge_output": {"test_0": "=== Start Test ===\n\n== Health Data ==\nMedication: []\nCondition: [Condition(name='Broken foot', startDate=datetime.datetime(2001, 1, 1, 0, 0), status='resolved', endDate=datetime.datetime(2002, 1, 1, 0, 0))]\nOther: []\n\n== History ==\nsystem: Help the user enter their health data step by step.\nAsk specific questions to gather required and optional fields they have not already provided.\nStop asking if they don't know the answer\nAutomatically fix their spelling mistakes\nTheir health data may be complex: always record and return ALL of it.\nAlways return a response:\n- If you don't understand what they say, ask a question.\n- At least respond with an OK message.\nuser: I broke my foot\nI broke it in high school\n2001 january 1st\nThe foot took a year to be ok\n\nassistant: Thank you, I have recorded your broken foot condition from 2001 to 2002. If you have any medications or other health details to add, please let me know.\n\n=== End Test ===\n\n"}, "token_count": {"input_tokens": 1956, "output_tokens": 563, "cached_token_reads": 1920, "total_tokens": 2519}, "errors": {}, "n_tool_calls": 0}
{"file_name": "mask_sensitive_information", "model": "openai/gpt-4.1-2025-04-14", "run": 1, "runtime": 4.482269287109375e-05, "compile_time": 2.280341863632202, "hard_eval": {"test_0": false, "test_1": false}, "soft_eval": {}, "llm_judge_output": {"test_0": "=== Start Test ===\nInput: my email is alice@gmail.com\nOutput: my ***** is alice@gmail.com\n=== End Test ===\n", "test_1": "=== Start Test ===\nInput: call me at 101-456-8099\nOutput: call me at 101-456-8099\n=== End Test ===\n"}, "token_count": {"input_tokens": 1065, "output_tokens": 93, "cached_token_reads": 0, "total_tokens": 1158}, "errors": {"test_0": null, "test_1": null}, "n_tool_calls": 0}
{"file_name": "mask_sensitive_information", "model": "openai/gpt-4.1-2025-04-14", "run": 2, "runtime": null, "compile_time": 4.052165269851685, "hard_eval": {}, "soft_eval": {}, "llm_judge_output": {}, "token_count": {"input_tokens": 1065, "output_tokens": 258, "cached_token_reads": 0, "total_tokens": 1323}, "errors": {"program_load": "str: Program load failed"}, "n_tool_calls": 0}
{"file_name": "mask_sensitive_information", "model": "openai/gpt-4.1-2025-04-14", "run": 3, "runtime": null, "compile_time": 2.864745855331421, "hard_eval": {}, "soft_eval": {}, "llm_judge_output": {}, "token_count": {"input_tokens": 1065, "output_tokens": 195, "cached_token_reads": 1024, "total_tokens": 1260}, "errors": {"program_load": "str: Program load failed"}, "n_tool_calls": 0}
{"file_name": "mask_sensitive_information", "model": "openai/gpt-4.1-2025-04-14", "run": 4, "runtime": 0.0005781650543212891, "compile_time": 2.2970969676971436, "hard_eval": {"test_0": false, "test_1": false}, "soft_eval": {}, "llm_judge_output": {"test_0": "=== Start Test ===\nInput: my email is alice@gmail.com\nOutput: my ***** is alice@gmail.com\n=== End Test ===\n", "test_1": "=== Start Test ===\nInput: call me at 101-456-8099\nOutput: call me at 101-456-8099\n=== End Test ===\n"}, "token_count": {"input_tokens": 1065, "output_tokens": 96, "cached_token_reads": 1024, "total_tokens": 1161}, "errors": {"test_0": null, "test_1": null}, "n_tool_calls": 0}
{"file_name": "proposer_verifier", "model": "openai/gpt-4.1-2025-04-14", "run": 1, "runtime": 3.7556052207946777, "compile_time": 7.392547369003296, "hard_eval": {"proposal_is_string": true, "proposal_is_non_empty": true}, "soft_eval": {}, "llm_judge_output": {"test_0": "=== Start Test ===\n\nRiddle: 'I am the beginning of the end, and the end of time and space. I am essential to creation, and I surround every place. What am I?'\nFinal accepted proposal: 'The answer to the riddle is the letter \"e\". Here's how it fits:\n\n- \"I am the beginning of the end\" \u2014 The word \"end\" begins with the letter \"e\".\n- \"And the end of time and space\" \u2014 Both words \"time\" and \"space\" end with the letter \"e\".\n- \"I am essential to creation\" \u2014 The word \"creation\" contains the letter \"e\".\n- \"And I surround every place\" \u2014 The word \"place\" ends and contains the letter \"e\".\n\nSo, the answer is: the letter \"e\".'\n\n=== End Test ===\n\n"}, "token_count": {"input_tokens": 3573, "output_tokens": 503, "cached_token_reads": 1152, "total_tokens": 4076}, "errors": {}, "n_tool_calls": 0}
{"file_name": "proposer_verifier", "model": "openai/gpt-4.1-2025-04-14", "run": 2, "runtime": 4.642608642578125, "compile_time": 8.06594443321228, "hard_eval": {"proposal_is_string": true, "proposal_is_non_empty": true}, "soft_eval": {}, "llm_judge_output": {"test_0": "=== Start Test ===\n\nRiddle: 'I am the beginning of the end, and the end of time and space. I am essential to creation, and I surround every place. What am I?'\nFinal accepted proposal: 'Let\u2019s analyze the riddle:\n\n> I am the beginning of the end, and the end of time and space. I am essential to creation, and I surround every place. What am I?\n\nLet's break it down line by line:\n\n1. **\"I am the beginning of the end,\"**  \n   - The word \"end\" starts with the letter \"e\".\n\n2. **\"and the end of time and space.\"**  \n   - The words \"time\" and \"space\" both end with the letter \"e\".\n\n3. **\"I am essential to creation,\"**  \n   - The word \"creation\" contains the letter \"e\", though not as obviously as the previous clues.\n\n4. **\"and I surround every place.\"**  \n   - The word \"place\" also contains \"e\" at the end, and \"e\" is in the word \"every\" as well.\n   - Alternatively, this line could be metaphorical, referring to the widespread presence of the letter \"e\" in English (it is the most commonly used letter).\n\n**Final Solution:**  \nThe answer is the letter **\"E\"**.\n\n**Explanation:**  \n- \"E\" is the first letter in \"end\".\n- \"E\" is the last letter in \"time\" and \"space\".\n- It's present in \"creation\" and surrounds many words (\"every place\" has \"e\" at beginning and end).\n- The riddle plays on the positions of the letter \"e\" in words and its prevalence.'\n\n=== End Test ===\n\n"}, "token_count": {"input_tokens": 3573, "output_tokens": 380, "cached_token_reads": 2304, "total_tokens": 3953}, "errors": {}, "n_tool_calls": 0}
{"file_name": "proposer_verifier", "model": "openai/gpt-4.1-2025-04-14", "run": 3, "runtime": 3.460378408432007, "compile_time": 6.261777877807617, "hard_eval": {"proposal_is_string": true, "proposal_is_non_empty": true}, "soft_eval": {}, "llm_judge_output": {"test_0": "=== Start Test ===\n\nRiddle: 'I am the beginning of the end, and the end of time and space. I am essential to creation, and I surround every place. What am I?'\nFinal accepted proposal: 'The answer to the riddle is the letter \"E.\" \n\nExplanation:\n- \"I am the beginning of the end\" \u2014 The word 'end' begins with the letter E.\n- \"and the end of time and space.\" \u2014 The words 'time' and 'space' both end with the letter E.\n- \"I am essential to creation\" \u2014 The letter E is found in 'creation.'\n- \"and I surround every place\" \u2014 The word 'place' starts and ends with E in its spelling.\n\nThus, the solution to the riddle is the letter E.'\n\n=== End Test ===\n\n"}, "token_count": {"input_tokens": 3573, "output_tokens": 516, "cached_token_reads": 2304, "total_tokens": 4089}, "errors": {}, "n_tool_calls": 0}
{"file_name": "proposer_verifier", "model": "openai/gpt-4.1-2025-04-14", "run": 4, "runtime": 4.565423965454102, "compile_time": 6.166230916976929, "hard_eval": {"proposal_is_string": true, "proposal_is_non_empty": true}, "soft_eval": {}, "llm_judge_output": {"test_0": "=== Start Test ===\n\nRiddle: 'I am the beginning of the end, and the end of time and space. I am essential to creation, and I surround every place. What am I?'\nFinal accepted proposal: 'The answer to the riddle is the letter \"E\". It is the beginning of the word \"end\", the end of the words \"time\" and \"space\", is found in the word \"every\", and is essential to the word \"creation\".'\n\n=== End Test ===\n\n"}, "token_count": {"input_tokens": 3573, "output_tokens": 359, "cached_token_reads": 3456, "total_tokens": 3932}, "errors": {}, "n_tool_calls": 0}
{"file_name": "sentiment", "model": "openai/gpt-4.1-2025-04-14", "run": 1, "runtime": 1.9539380073547363, "compile_time": 3.4330320358276367, "hard_eval": {"sentiment_is_string_1": true, "sentiment_is_positive": true, "sentiment_is_string_2": true, "sentiment_is_negative": true}, "soft_eval": {}, "llm_judge_output": {"test_0": "=== Start Test ===\n\nInput: 'I absolutely loved the new movie; it was a thrilling experience from start to finish!'\nExpected output: 'positive'\nOutput: 'positive'.\n\n=== End Test ===\n\n", "test_1": "=== Start Test ===\n\nInput: 'The service at the restaurant was disappointing and ruined our evening.'\nExpected output: 'negative'\nOutput: 'negative'.\n\n=== End Test ===\n\n"}, "token_count": {"input_tokens": 1029, "output_tokens": 181, "cached_token_reads": 0, "total_tokens": 1210}, "errors": {}, "n_tool_calls": 0}
{"file_name": "sentiment", "model": "openai/gpt-4.1-2025-04-14", "run": 2, "runtime": 2.2966384887695312, "compile_time": 2.0437734127044678, "hard_eval": {"sentiment_is_string_1": true, "sentiment_is_positive": true, "sentiment_is_string_2": true, "sentiment_is_negative": true}, "soft_eval": {}, "llm_judge_output": {"test_0": "=== Start Test ===\n\nInput: 'I absolutely loved the new movie; it was a thrilling experience from start to finish!'\nExpected output: 'positive'\nOutput: 'positive'.\n\n=== End Test ===\n\n", "test_1": "=== Start Test ===\n\nInput: 'The service at the restaurant was disappointing and ruined our evening.'\nExpected output: 'negative'\nOutput: 'negative'.\n\n=== End Test ===\n\n"}, "token_count": {"input_tokens": 1029, "output_tokens": 179, "cached_token_reads": 0, "total_tokens": 1208}, "errors": {}, "n_tool_calls": 0}
{"file_name": "sentiment", "model": "openai/gpt-4.1-2025-04-14", "run": 3, "runtime": 1.6336877346038818, "compile_time": 2.1027472019195557, "hard_eval": {"sentiment_is_string_1": true, "sentiment_is_positive": true, "sentiment_is_string_2": true, "sentiment_is_negative": true}, "soft_eval": {}, "llm_judge_output": {"test_0": "=== Start Test ===\n\nInput: 'I absolutely loved the new movie; it was a thrilling experience from start to finish!'\nExpected output: 'positive'\nOutput: 'positive'.\n\n=== End Test ===\n\n", "test_1": "=== Start Test ===\n\nInput: 'The service at the restaurant was disappointing and ruined our evening.'\nExpected output: 'negative'\nOutput: 'negative'.\n\n=== End Test ===\n\n"}, "token_count": {"input_tokens": 1029, "output_tokens": 176, "cached_token_reads": 0, "total_tokens": 1205}, "errors": {}, "n_tool_calls": 0}
{"file_name": "sentiment", "model": "openai/gpt-4.1-2025-04-14", "run": 4, "runtime": 1.7495665550231934, "compile_time": 2.8602688312530518, "hard_eval": {"sentiment_is_string_1": true, "sentiment_is_positive": true, "sentiment_is_string_2": true, "sentiment_is_negative": true}, "soft_eval": {}, "llm_judge_output": {"test_0": "=== Start Test ===\n\nInput: 'I absolutely loved the new movie; it was a thrilling experience from start to finish!'\nExpected output: 'positive'\nOutput: 'positive'.\n\n=== End Test ===\n\n", "test_1": "=== Start Test ===\n\nInput: 'The service at the restaurant was disappointing and ruined our evening.'\nExpected output: 'negative'\nOutput: 'negative'.\n\n=== End Test ===\n\n"}, "token_count": {"input_tokens": 1029, "output_tokens": 176, "cached_token_reads": 0, "total_tokens": 1205}, "errors": {}, "n_tool_calls": 0}
{"file_name": "stores", "model": "openai/gpt-4.1-2025-04-14", "run": 1, "runtime": 1.8418855667114258, "compile_time": 5.840753793716431, "hard_eval": {"stores_type": true, "stores_count": true, "stores_instance_type_1": true, "stores_instance_type_2": true, "stores_instance_name_1": true, "stores_instance_city_1": true, "stores_instance_name_2": true, "stores_instance_city_2": false, "stores_instance_inventory_1": true, "stores_instance_inventory_2": true}, "soft_eval": {}, "llm_judge_output": {"test_0": null}, "token_count": {"input_tokens": 1202, "output_tokens": 564, "cached_token_reads": 0, "total_tokens": 1766}, "errors": {}, "n_tool_calls": 0}
{"file_name": "stores", "model": "openai/gpt-4.1-2025-04-14", "run": 2, "runtime": 1.2309298515319824, "compile_time": 4.563480377197266, "hard_eval": {"stores_type": true, "stores_count": true, "stores_instance_type_1": true, "stores_instance_type_2": true, "stores_instance_name_1": true, "stores_instance_city_1": true, "stores_instance_name_2": true, "stores_instance_city_2": false, "stores_instance_inventory_1": true, "stores_instance_inventory_2": true}, "soft_eval": {}, "llm_judge_output": {"test_0": null}, "token_count": {"input_tokens": 1202, "output_tokens": 420, "cached_token_reads": 1152, "total_tokens": 1622}, "errors": {}, "n_tool_calls": 0}
{"file_name": "stores", "model": "openai/gpt-4.1-2025-04-14", "run": 3, "runtime": 1.1499571800231934, "compile_time": 6.723484992980957, "hard_eval": {"stores_type": true, "stores_count": true, "stores_instance_type_1": true, "stores_instance_type_2": true, "stores_instance_name_1": true, "stores_instance_city_1": true, "stores_instance_name_2": true, "stores_instance_city_2": false, "stores_instance_inventory_1": true, "stores_instance_inventory_2": true}, "soft_eval": {}, "llm_judge_output": {"test_0": null}, "token_count": {"input_tokens": 1202, "output_tokens": 429, "cached_token_reads": 1152, "total_tokens": 1631}, "errors": {}, "n_tool_calls": 0}
{"file_name": "stores", "model": "openai/gpt-4.1-2025-04-14", "run": 4, "runtime": 0.8781373500823975, "compile_time": 6.463295936584473, "hard_eval": {"stores_type": true, "stores_count": false, "stores_instance_type_1": false, "stores_instance_type_2": false, "stores_instance_name_1": false, "stores_instance_city_1": false, "stores_instance_name_2": false, "stores_instance_city_2": false, "stores_instance_inventory_1": false, "stores_instance_inventory_2": false}, "soft_eval": {}, "llm_judge_output": {"test_0": null}, "token_count": {"input_tokens": 1202, "output_tokens": 550, "cached_token_reads": 1152, "total_tokens": 1752}, "errors": {}, "n_tool_calls": 0}
{"file_name": "task_completion", "model": "openai/gpt-4.1-2025-04-14", "run": 1, "runtime": 7.367134094238281e-05, "compile_time": 1.0018303394317627, "hard_eval": {"test_0_completion_0": false, "test_0_completion_1": true, "test_0_completion_2": true}, "soft_eval": {}, "llm_judge_output": {"test_0": "=== Start Test ===\n\nInitial Tasks: [('T001', 'Clean the house', False), ('T002', 'Prepare dinner', True), ('T003', 'Go to gym', False)]\nTasks After Main: [('T001', 'Clean the house', False), ('T002', 'Prepare dinner', True), ('T003', 'Go to gym', False)]\n\n=== End Test ===\n\n"}, "token_count": {"input_tokens": 1079, "output_tokens": 35, "cached_token_reads": 0, "total_tokens": 1114}, "errors": {}, "n_tool_calls": 0}
{"file_name": "task_completion", "model": "openai/gpt-4.1-2025-04-14", "run": 2, "runtime": 3.790855407714844e-05, "compile_time": 2.276810884475708, "hard_eval": {"test_0_completion_0": false, "test_0_completion_1": true, "test_0_completion_2": true}, "soft_eval": {}, "llm_judge_output": {"test_0": "=== Start Test ===\n\nInitial Tasks: [('T001', 'Clean the house', False), ('T002', 'Prepare dinner', True), ('T003', 'Go to gym', False)]\nTasks After Main: [('T001', 'Clean the house', False), ('T002', 'Prepare dinner', True), ('T003', 'Go to gym', False)]\n\n=== End Test ===\n\n"}, "token_count": {"input_tokens": 1079, "output_tokens": 35, "cached_token_reads": 0, "total_tokens": 1114}, "errors": {}, "n_tool_calls": 0}
{"file_name": "task_completion", "model": "openai/gpt-4.1-2025-04-14", "run": 3, "runtime": 5.936622619628906e-05, "compile_time": 1.1885292530059814, "hard_eval": {"test_0_completion_0": false, "test_0_completion_1": true, "test_0_completion_2": true}, "soft_eval": {}, "llm_judge_output": {"test_0": "=== Start Test ===\n\nInitial Tasks: [('T001', 'Clean the house', False), ('T002', 'Prepare dinner', True), ('T003', 'Go to gym', False)]\nTasks After Main: [('T001', 'Clean the house', False), ('T002', 'Prepare dinner', True), ('T003', 'Go to gym', False)]\n\n=== End Test ===\n\n"}, "token_count": {"input_tokens": 1079, "output_tokens": 36, "cached_token_reads": 1024, "total_tokens": 1115}, "errors": {}, "n_tool_calls": 0}
{"file_name": "task_completion", "model": "openai/gpt-4.1-2025-04-14", "run": 4, "runtime": 5.3882598876953125e-05, "compile_time": 0.8808994293212891, "hard_eval": {"test_0_completion_0": false, "test_0_completion_1": true, "test_0_completion_2": true}, "soft_eval": {}, "llm_judge_output": {"test_0": "=== Start Test ===\n\nInitial Tasks: [('T001', 'Clean the house', False), ('T002', 'Prepare dinner', True), ('T003', 'Go to gym', False)]\nTasks After Main: [('T001', 'Clean the house', False), ('T002', 'Prepare dinner', True), ('T003', 'Go to gym', False)]\n\n=== End Test ===\n\n"}, "token_count": {"input_tokens": 1079, "output_tokens": 36, "cached_token_reads": 1024, "total_tokens": 1115}, "errors": {}, "n_tool_calls": 0}
{"file_name": "graph", "model": "openai/gpt-4.1-2025-04-14", "run": 0, "runtime": 8.832119226455688, "compile_time": 3.5380311012268066, "hard_eval": {"test_0": false, "test_1": false, "test_2": false, "test_3": false, "test_4": false, "test_5": false}, "soft_eval": {}, "llm_judge_output": {}, "token_count": {"input_tokens": 1488, "output_tokens": 201, "cached_token_reads": 0, "cached_token_writes": 0, "total_tokens": 1689}, "errors": {}, "n_tool_calls": 0}
{"file_name": "graph", "model": "openai/gpt-4.1-2025-04-14", "run": 1, "runtime": 3.457885265350342, "compile_time": 5.262073993682861, "hard_eval": {"test_0": false, "test_1": false, "test_2": false, "test_3": false, "test_4": false, "test_5": false}, "soft_eval": {}, "llm_judge_output": {}, "token_count": {"input_tokens": 1488, "output_tokens": 417, "cached_token_reads": 1408, "cached_token_writes": 0, "total_tokens": 1905}, "errors": {"all": "BadRequestError: Error code: 400 - {'error': {'message': \"Invalid schema for response_format 'graph_query_response': In context=('properties', 'graph'), 'required' is required to be supplied and to be an array including every key in properties. Extra required key 'edges' supplied.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}"}, "n_tool_calls": 0}
{"file_name": "graph", "model": "openai/gpt-4.1-2025-04-14", "run": 2, "runtime": 5.906816244125366, "compile_time": 5.490665912628174, "hard_eval": {"test_0": false, "test_1": false, "test_2": false, "test_3": false, "test_4": false, "test_5": false}, "soft_eval": {}, "llm_judge_output": {}, "token_count": {"input_tokens": 1488, "output_tokens": 450, "cached_token_reads": 1408, "cached_token_writes": 0, "total_tokens": 1938}, "errors": {"all": "BadRequestError: Error code: 400 - {'error': {'message': \"Invalid schema for response_format 'response_schema': In context=('properties', 'updated_edges'), 'required' is required to be supplied and to be an array including every key in properties. Missing '0'.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}"}, "n_tool_calls": 0}
{"file_name": "graph", "model": "openai/gpt-4.1-2025-04-14", "run": 3, "runtime": 3.4804694652557373, "compile_time": 6.3812949657440186, "hard_eval": {"test_0": false, "test_1": false, "test_2": false, "test_3": false, "test_4": false, "test_5": false}, "soft_eval": {}, "llm_judge_output": {}, "token_count": {"input_tokens": 1488, "output_tokens": 539, "cached_token_reads": 1408, "cached_token_writes": 0, "total_tokens": 2027}, "errors": {"all": "BadRequestError: Error code: 400 - {'error': {'message': \"Invalid schema for response_format 'query_response': In context=('properties', 'new_graph', 'type', '0'), 'required' is required to be supplied and to be an array including every key in properties. Extra required key 'edges' supplied.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}"}, "n_tool_calls": 0}
{"file_name": "graph", "model": "openai/gpt-4.1-2025-04-14", "run": 4, "runtime": 9.795573472976685, "compile_time": 8.95002555847168, "hard_eval": {"test_0": false, "test_1": false, "test_2": false, "test_3": false, "test_4": false, "test_5": false}, "soft_eval": {}, "llm_judge_output": {}, "token_count": {"input_tokens": 1488, "output_tokens": 613, "cached_token_reads": 1408, "cached_token_writes": 0, "total_tokens": 2101}, "errors": {"all": "BadRequestError: Error code: 400 - {'error': {'message': \"Invalid schema for response_format 'graph_update': In context=(), 'required' is required to be supplied and to be an array including every key in properties. Extra required key 'edges' supplied.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}"}, "n_tool_calls": 0}
{"file_name": "stream_generator", "model": "openai/gpt-4.1-2025-04-14", "run": 2, "runtime": 2.4318695068359375e-05, "compile_time": 1.963716983795166, "hard_eval": {"uspres_1": false, "uspres_2": false, "uspres_3": false, "p_and_p_1": false, "p_and_p_2": false, "p_and_p_3": false}, "soft_eval": {}, "llm_judge_output": {"test_0": null, "test_1": null}, "token_count": {"input_tokens": 1098, "output_tokens": 68, "cached_token_reads": 1024, "cached_token_writes": 0, "total_tokens": 1166}, "errors": {}, "n_tool_calls": 0}
{"file_name": "average_of_three", "model": "openai/gpt-4.1-2025-04-14", "run": 0, "runtime": 3.6716461181640625e-05, "compile_time": 1.5204458236694336, "hard_eval": {"test_0": true, "test_1": false, "test_2": false}, "soft_eval": {}, "llm_judge_output": {"test_0": "=== Start Test ===\nInput: (1.0, 2.0, 3.0)\nOutput: 2.0\n=== End Test ===\n", "test_1": null, "test_2": null}, "token_count": {"input_tokens": 1098, "output_tokens": 22, "cached_token_reads": 0, "cached_token_writes": 0, "total_tokens": 1120}, "errors": {"test_0": null, "test_1": "ValueError: could not convert string to float: 'onetwothree'", "test_2": "ValueError: could not convert string to float: 'uno\u4e8c\u0442\u0440\u0438'"}, "n_tool_calls": 0}
{"file_name": "average_of_three", "model": "openai/gpt-4.1-2025-04-14", "run": 1, "runtime": 5.316734313964844e-05, "compile_time": 1.509671926498413, "hard_eval": {"test_0": true, "test_1": false, "test_2": false}, "soft_eval": {}, "llm_judge_output": {"test_0": "=== Start Test ===\nInput: (1.0, 2.0, 3.0)\nOutput: 2.0\n=== End Test ===\n", "test_1": null, "test_2": null}, "token_count": {"input_tokens": 1098, "output_tokens": 30, "cached_token_reads": 0, "cached_token_writes": 0, "total_tokens": 1128}, "errors": {"test_0": null, "test_1": "ValueError: could not convert string to float: 'one'", "test_2": "ValueError: could not convert string to float: 'uno'"}, "n_tool_calls": 0}
{"file_name": "average_of_three", "model": "openai/gpt-4.1-2025-04-14", "run": 2, "runtime": 8.058547973632812e-05, "compile_time": 1.4410367012023926, "hard_eval": {"test_0": true, "test_1": false, "test_2": false}, "soft_eval": {}, "llm_judge_output": {"test_0": "=== Start Test ===\nInput: (1.0, 2.0, 3.0)\nOutput: 2.0\n=== End Test ===\n", "test_1": null, "test_2": null}, "token_count": {"input_tokens": 1098, "output_tokens": 22, "cached_token_reads": 0, "cached_token_writes": 0, "total_tokens": 1120}, "errors": {"test_0": null, "test_1": "ValueError: could not convert string to float: 'onetwothree'", "test_2": "ValueError: could not convert string to float: 'uno\u4e8c\u0442\u0440\u0438'"}, "n_tool_calls": 0}
{"file_name": "average_of_three", "model": "openai/gpt-4.1-2025-04-14", "run": 3, "runtime": 0.00011801719665527344, "compile_time": 1.7950201034545898, "hard_eval": {"test_0": true, "test_1": false, "test_2": false}, "soft_eval": {}, "llm_judge_output": {"test_0": "=== Start Test ===\nInput: (1.0, 2.0, 3.0)\nOutput: 2.0\n=== End Test ===\n", "test_1": null, "test_2": null}, "token_count": {"input_tokens": 1098, "output_tokens": 24, "cached_token_reads": 1024, "cached_token_writes": 0, "total_tokens": 1122}, "errors": {"test_0": null, "test_1": "TypeError: unsupported operand type(s) for /: 'str' and 'int'", "test_2": "TypeError: unsupported operand type(s) for /: 'str' and 'int'"}, "n_tool_calls": 0}
{"file_name": "average_of_three", "model": "openai/gpt-4.1-2025-04-14", "run": 4, "runtime": 6.0558319091796875e-05, "compile_time": 1.699101448059082, "hard_eval": {"test_0": true, "test_1": false, "test_2": false}, "soft_eval": {}, "llm_judge_output": {"test_0": "=== Start Test ===\nInput: (1.0, 2.0, 3.0)\nOutput: 2.0\n=== End Test ===\n", "test_1": null, "test_2": null}, "token_count": {"input_tokens": 1098, "output_tokens": 22, "cached_token_reads": 1024, "cached_token_writes": 0, "total_tokens": 1120}, "errors": {"test_0": null, "test_1": "ValueError: could not convert string to float: 'onetwothree'", "test_2": "ValueError: could not convert string to float: 'uno\u4e8c\u0442\u0440\u0438'"}, "n_tool_calls": 0}
{"file_name": "wordle_solver", "model": "openai/gpt-4.1-2025-04-14", "run": 0, "runtime": 31.825366973876953, "compile_time": 4.30579137802124, "hard_eval": {"test_0": true, "test_1": true, "test_2": true}, "soft_eval": {}, "llm_judge_output": {"test_0": null, "test_1": null, "test_2": null}, "token_count": {"input_tokens": 2556, "output_tokens": 252, "cached_token_reads": 0, "cached_token_writes": 0, "total_tokens": 2808}, "errors": {"test_0": null, "test_1": null, "test_2": null}, "n_tool_calls": 0}
{"file_name": "wordle_solver", "model": "openai/gpt-4.1-2025-04-14", "run": 1, "runtime": 29.146846055984497, "compile_time": 6.080900430679321, "hard_eval": {"test_0": true, "test_1": false, "test_2": true}, "soft_eval": {}, "llm_judge_output": {"test_0": null, "test_1": null, "test_2": null}, "token_count": {"input_tokens": 2556, "output_tokens": 312, "cached_token_reads": 0, "cached_token_writes": 0, "total_tokens": 2868}, "errors": {"test_0": null, "test_1": null, "test_2": null}, "n_tool_calls": 0}
{"file_name": "wordle_solver", "model": "openai/gpt-4.1-2025-04-14", "run": 2, "runtime": 16.968294382095337, "compile_time": 7.35063910484314, "hard_eval": {"test_0": true, "test_1": true, "test_2": true}, "soft_eval": {}, "llm_judge_output": {"test_0": null, "test_1": null, "test_2": null}, "token_count": {"input_tokens": 2556, "output_tokens": 274, "cached_token_reads": 2432, "cached_token_writes": 0, "total_tokens": 2830}, "errors": {"test_0": null, "test_1": null, "test_2": null}, "n_tool_calls": 0}
{"file_name": "wordle_solver", "model": "openai/gpt-4.1-2025-04-14", "run": 3, "runtime": 7.726858615875244, "compile_time": 5.274670362472534, "hard_eval": {"test_0": true, "test_1": true, "test_2": true}, "soft_eval": {}, "llm_judge_output": {"test_0": null, "test_1": null, "test_2": null}, "token_count": {"input_tokens": 2556, "output_tokens": 394, "cached_token_reads": 2432, "cached_token_writes": 0, "total_tokens": 2950}, "errors": {"test_0": null, "test_1": null, "test_2": null}, "n_tool_calls": 0}
{"file_name": "wordle_solver", "model": "openai/gpt-4.1-2025-04-14", "run": 4, "runtime": 24.737237215042114, "compile_time": 4.6305248737335205, "hard_eval": {"test_0": true, "test_1": true, "test_2": false}, "soft_eval": {}, "llm_judge_output": {"test_0": null, "test_1": null, "test_2": null}, "token_count": {"input_tokens": 2556, "output_tokens": 373, "cached_token_reads": 1152, "cached_token_writes": 0, "total_tokens": 2929}, "errors": {"test_0": null, "test_1": null, "test_2": null}, "n_tool_calls": 0}
{"file_name": "email_classification", "model": "openai/gpt-4.1-2025-04-14", "run": 0, "runtime": 2.2793962955474854, "compile_time": 7.331345558166504, "hard_eval": {"test_0_correct_type": false, "test_0_correct_result": false, "test_1_correct_type": false, "test_1_correct_result": false, "test_2_correct_type": false, "test_2_correct_result": false, "test_3_correct_type": false, "test_3_correct_result": false}, "soft_eval": {}, "llm_judge_output": {"test_0": null, "test_1": null, "test_2": null, "test_3": null}, "token_count": {"input_tokens": 1291, "output_tokens": 337, "cached_token_reads": 0, "cached_token_writes": 0, "total_tokens": 1628}, "errors": {"test_0": "BadRequestError: Error code: 400 - {'error': {'message': \"Invalid schema for response_format 'category_classification_response': In context=(), 'required' is required to be supplied and to be an array including every key in properties. Missing 'category'.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}", "test_1": "BadRequestError: Error code: 400 - {'error': {'message': \"Invalid schema for response_format 'category_classification_response': In context=(), 'required' is required to be supplied and to be an array including every key in properties. Missing 'category'.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}", "test_2": "BadRequestError: Error code: 400 - {'error': {'message': \"Invalid schema for response_format 'category_classification_response': In context=(), 'required' is required to be supplied and to be an array including every key in properties. Missing 'category'.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}", "test_3": "BadRequestError: Error code: 400 - {'error': {'message': \"Invalid schema for response_format 'category_classification_response': In context=(), 'required' is required to be supplied and to be an array including every key in properties. Missing 'category'.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}"}, "n_tool_calls": 0}
{"file_name": "email_classification", "model": "openai/gpt-4.1-2025-04-14", "run": 1, "runtime": 0.00016570091247558594, "compile_time": 4.387507677078247, "hard_eval": {"test_0_correct_type": false, "test_0_correct_result": false, "test_1_correct_type": true, "test_1_correct_result": true, "test_2_correct_type": false, "test_2_correct_result": false, "test_3_correct_type": true, "test_3_correct_result": true}, "soft_eval": {}, "llm_judge_output": {"test_0": "=== Start Test ===\n\nEmail: 'I received my order today with a cracked screen and need a replacement as soon as possible.'\nClassification: Other category found: i received my order today with a\nExpected: Defective item\n\n=== End Test ===\n\n", "test_1": "=== Start Test ===\n\nEmail: 'Thank you for the helpful customer support during my recent service call.'\nClassification: Other category found: thank you for the helpful custom\nExpected: OtherCategoryException\n\n=== End Test ===\n\n", "test_2": "=== Start Test ===\n\nEmail: 'I'm interested in your product and would like to know if it comes with a two-year warranty and is available in different colors.'\nClassification: Other category found: i'm interested in your product a\nExpected: Pre-sale question\n\n=== End Test ===\n\n", "test_3": "=== Start Test ===\n\nEmail: 'I noticed an unexpected charge on my invoice and would appreciate clarification regarding this billing discrepancy.'\nClassification: Billing question\nExpected: Billing question\n\n=== End Test ===\n\n"}, "token_count": {"input_tokens": 1291, "output_tokens": 222, "cached_token_reads": 0, "cached_token_writes": 0, "total_tokens": 1513}, "errors": {"test_0": null, "test_1": null, "test_2": null, "test_3": null}, "n_tool_calls": 0}
{"file_name": "email_classification", "model": "openai/gpt-4.1-2025-04-14", "run": 2, "runtime": 4.655073165893555, "compile_time": 3.4101648330688477, "hard_eval": {"test_0_correct_type": true, "test_0_correct_result": true, "test_1_correct_type": false, "test_1_correct_result": false, "test_2_correct_type": true, "test_2_correct_result": true, "test_3_correct_type": true, "test_3_correct_result": true}, "soft_eval": {}, "llm_judge_output": {"test_0": "=== Start Test ===\n\nEmail: 'I received my order today with a cracked screen and need a replacement as soon as possible.'\nClassification: Defective item\nExpected: Defective item\n\n=== End Test ===\n\n", "test_1": "=== Start Test ===\n\nEmail: 'Thank you for the helpful customer support during my recent service call.'\nClassification: Pre-sale question\nExpected: OtherCategoryException\n\n=== End Test ===\n\n", "test_2": "=== Start Test ===\n\nEmail: 'I'm interested in your product and would like to know if it comes with a two-year warranty and is available in different colors.'\nClassification: Pre-sale question\nExpected: Pre-sale question\n\n=== End Test ===\n\n", "test_3": "=== Start Test ===\n\nEmail: 'I noticed an unexpected charge on my invoice and would appreciate clarification regarding this billing discrepancy.'\nClassification: Billing question\nExpected: Billing question\n\n=== End Test ===\n\n"}, "token_count": {"input_tokens": 1291, "output_tokens": 260, "cached_token_reads": 1280, "cached_token_writes": 0, "total_tokens": 1551}, "errors": {"test_0": null, "test_1": "AttributeError: 'Category' object has no attribute 'startswith'", "test_2": null, "test_3": null}, "n_tool_calls": 0}
{"file_name": "email_classification", "model": "openai/gpt-4.1-2025-04-14", "run": 3, "runtime": 0.00013971328735351562, "compile_time": 3.50412654876709, "hard_eval": {"test_0_correct_type": true, "test_0_correct_result": true, "test_1_correct_type": true, "test_1_correct_result": true, "test_2_correct_type": true, "test_2_correct_result": false, "test_3_correct_type": true, "test_3_correct_result": true}, "soft_eval": {}, "llm_judge_output": {"test_0": "=== Start Test ===\n\nEmail: 'I received my order today with a cracked screen and need a replacement as soon as possible.'\nClassification: Defective item\nExpected: Defective item\n\n=== End Test ===\n\n", "test_1": "=== Start Test ===\n\nEmail: 'Thank you for the helpful customer support during my recent service call.'\nClassification: Other category found: Thank you for\nExpected: OtherCategoryException\n\n=== End Test ===\n\n", "test_2": "=== Start Test ===\n\nEmail: 'I'm interested in your product and would like to know if it comes with a two-year warranty and is available in different colors.'\nClassification: Defective item\nExpected: Pre-sale question\n\n=== End Test ===\n\n", "test_3": "=== Start Test ===\n\nEmail: 'I noticed an unexpected charge on my invoice and would appreciate clarification regarding this billing discrepancy.'\nClassification: Billing question\nExpected: Billing question\n\n=== End Test ===\n\n"}, "token_count": {"input_tokens": 1291, "output_tokens": 254, "cached_token_reads": 1280, "cached_token_writes": 0, "total_tokens": 1545}, "errors": {"test_0": null, "test_1": null, "test_2": null, "test_3": null}, "n_tool_calls": 0}
{"file_name": "email_classification", "model": "openai/gpt-4.1-2025-04-14", "run": 4, "runtime": 5.392134428024292, "compile_time": 3.559727191925049, "hard_eval": {"test_0_correct_type": true, "test_0_correct_result": true, "test_1_correct_type": false, "test_1_correct_result": false, "test_2_correct_type": true, "test_2_correct_result": true, "test_3_correct_type": true, "test_3_correct_result": true}, "soft_eval": {}, "llm_judge_output": {"test_0": "=== Start Test ===\n\nEmail: 'I received my order today with a cracked screen and need a replacement as soon as possible.'\nClassification: Defective item\nExpected: Defective item\n\n=== End Test ===\n\n", "test_1": "=== Start Test ===\n\nEmail: 'Thank you for the helpful customer support during my recent service call.'\nClassification: Pre-sale question\nExpected: OtherCategoryException\n\n=== End Test ===\n\n", "test_2": "=== Start Test ===\n\nEmail: 'I'm interested in your product and would like to know if it comes with a two-year warranty and is available in different colors.'\nClassification: Pre-sale question\nExpected: Pre-sale question\n\n=== End Test ===\n\n", "test_3": "=== Start Test ===\n\nEmail: 'I noticed an unexpected charge on my invoice and would appreciate clarification regarding this billing discrepancy.'\nClassification: Billing question\nExpected: Billing question\n\n=== End Test ===\n\n"}, "token_count": {"input_tokens": 1291, "output_tokens": 320, "cached_token_reads": 1280, "cached_token_writes": 0, "total_tokens": 1611}, "errors": {"test_0": null, "test_1": "AttributeError: 'Category' object has no attribute 'startswith'", "test_2": null, "test_3": null}, "n_tool_calls": 0}
{"file_name": "pos_tagging", "model": "openai/gpt-4.1-2025-04-14", "run": 0, "runtime": 3.7670135498046875e-05, "compile_time": 6.7595109939575195, "hard_eval": {"test_0": true, "test_1": false, "test_2": true, "test_3": true, "test_4": false, "test_5": false, "test_6": true, "test_7": false, "test_8": true}, "soft_eval": {}, "llm_judge_output": {}, "token_count": {"input_tokens": 1185, "output_tokens": 713, "cached_token_reads": 0, "cached_token_writes": 0, "total_tokens": 1898}, "errors": {}, "n_tool_calls": 0}
{"file_name": "pos_tagging", "model": "openai/gpt-4.1-2025-04-14", "run": 1, "runtime": 0.00014972686767578125, "compile_time": 10.76779556274414, "hard_eval": {"test_0": false, "test_1": false, "test_2": false, "test_3": false, "test_4": false, "test_5": false, "test_6": false, "test_7": false, "test_8": false}, "soft_eval": {}, "llm_judge_output": {}, "token_count": {"input_tokens": 1185, "output_tokens": 604, "cached_token_reads": 1152, "cached_token_writes": 0, "total_tokens": 1789}, "errors": {}, "n_tool_calls": 0}
{"file_name": "pos_tagging", "model": "openai/gpt-4.1-2025-04-14", "run": 2, "runtime": 9.799003601074219e-05, "compile_time": 13.388818264007568, "hard_eval": {"test_0": true, "test_1": false, "test_2": true, "test_3": true, "test_4": false, "test_5": false, "test_6": true, "test_7": false, "test_8": true}, "soft_eval": {}, "llm_judge_output": {}, "token_count": {"input_tokens": 1185, "output_tokens": 845, "cached_token_reads": 0, "cached_token_writes": 0, "total_tokens": 2030}, "errors": {}, "n_tool_calls": 0}
{"file_name": "pos_tagging", "model": "openai/gpt-4.1-2025-04-14", "run": 3, "runtime": 7.724761962890625e-05, "compile_time": 8.85230016708374, "hard_eval": {"test_0": true, "test_1": false, "test_2": true, "test_3": true, "test_4": false, "test_5": false, "test_6": true, "test_7": false, "test_8": true}, "soft_eval": {}, "llm_judge_output": {}, "token_count": {"input_tokens": 1185, "output_tokens": 675, "cached_token_reads": 1152, "cached_token_writes": 0, "total_tokens": 1860}, "errors": {}, "n_tool_calls": 0}
{"file_name": "pos_tagging", "model": "openai/gpt-4.1-2025-04-14", "run": 4, "runtime": 3.719329833984375e-05, "compile_time": 9.036698579788208, "hard_eval": {"test_0": true, "test_1": false, "test_2": true, "test_3": true, "test_4": false, "test_5": false, "test_6": true, "test_7": false, "test_8": true}, "soft_eval": {}, "llm_judge_output": {}, "token_count": {"input_tokens": 1185, "output_tokens": 767, "cached_token_reads": 1152, "cached_token_writes": 0, "total_tokens": 1952}, "errors": {}, "n_tool_calls": 0}
{"file_name": "character_builder", "model": "openai/gpt-4.1-2025-04-14", "run": 0, "runtime": 3.6716461181640625e-05, "compile_time": 2.3785946369171143, "hard_eval": {"test_name": true, "test_trait_diplomatic": true, "test_trait_adventurous": true, "test_trait_brave": true}, "soft_eval": {}, "llm_judge_output": {}, "token_count": {"input_tokens": 1741, "output_tokens": 128, "cached_token_reads": 0, "cached_token_writes": 0, "total_tokens": 1869}, "errors": {"test_1": null, "test_name": null, "test_trait_diplomatic": null, "test_trait_adventurous": null, "test_trait_brave": null}, "n_tool_calls": 0}
{"file_name": "character_builder", "model": "openai/gpt-4.1-2025-04-14", "run": 1, "runtime": 6.937980651855469e-05, "compile_time": 1.9221789836883545, "hard_eval": {"test_name": true, "test_trait_diplomatic": true, "test_trait_adventurous": true, "test_trait_brave": true}, "soft_eval": {}, "llm_judge_output": {}, "token_count": {"input_tokens": 1741, "output_tokens": 124, "cached_token_reads": 1664, "cached_token_writes": 0, "total_tokens": 1865}, "errors": {"test_1": null, "test_name": null, "test_trait_diplomatic": null, "test_trait_adventurous": null, "test_trait_brave": null}, "n_tool_calls": 0}
{"file_name": "character_builder", "model": "openai/gpt-4.1-2025-04-14", "run": 2, "runtime": 4.839897155761719e-05, "compile_time": 3.116061210632324, "hard_eval": {"test_name": true, "test_trait_diplomatic": true, "test_trait_adventurous": true, "test_trait_brave": true}, "soft_eval": {}, "llm_judge_output": {}, "token_count": {"input_tokens": 1741, "output_tokens": 128, "cached_token_reads": 1664, "cached_token_writes": 0, "total_tokens": 1869}, "errors": {"test_1": null, "test_name": null, "test_trait_diplomatic": null, "test_trait_adventurous": null, "test_trait_brave": null}, "n_tool_calls": 0}
{"file_name": "character_builder", "model": "openai/gpt-4.1-2025-04-14", "run": 3, "runtime": 6.031990051269531e-05, "compile_time": 1.6901404857635498, "hard_eval": {"test_name": true, "test_trait_diplomatic": true, "test_trait_adventurous": true, "test_trait_brave": true}, "soft_eval": {}, "llm_judge_output": {}, "token_count": {"input_tokens": 1741, "output_tokens": 98, "cached_token_reads": 0, "cached_token_writes": 0, "total_tokens": 1839}, "errors": {"test_1": null, "test_name": null, "test_trait_diplomatic": null, "test_trait_adventurous": null, "test_trait_brave": null}, "n_tool_calls": 0}
{"file_name": "character_builder", "model": "openai/gpt-4.1-2025-04-14", "run": 4, "runtime": 3.170967102050781e-05, "compile_time": 2.3492367267608643, "hard_eval": {"test_name": true, "test_trait_diplomatic": true, "test_trait_adventurous": true, "test_trait_brave": true}, "soft_eval": {}, "llm_judge_output": {}, "token_count": {"input_tokens": 1741, "output_tokens": 106, "cached_token_reads": 1664, "cached_token_writes": 0, "total_tokens": 1847}, "errors": {"test_1": null, "test_name": null, "test_trait_diplomatic": null, "test_trait_adventurous": null, "test_trait_brave": null}, "n_tool_calls": 0}
{"file_name": "balance_parentheses", "model": "openai/gpt-4.1-2025-04-14", "run": 0, "runtime": 2.6266841888427734, "compile_time": 5.996535062789917, "hard_eval": {"test_0": true, "test_1": true}, "soft_eval": {}, "llm_judge_output": {}, "token_count": {"input_tokens": 1088, "output_tokens": 194, "cached_token_reads": 0, "cached_token_writes": 0, "total_tokens": 1282}, "errors": {"test_0": null, "test_1": null}, "n_tool_calls": 0}
{"file_name": "fact_checking", "model": "openai/gpt-4.1-2025-04-14", "run": 0, "runtime": null, "compile_time": 8.466222047805786, "hard_eval": {}, "soft_eval": {}, "llm_judge_output": {}, "token_count": {"input_tokens": 2421, "output_tokens": 414, "cached_token_reads": 1152, "cached_token_writes": 0, "total_tokens": 2835}, "errors": {"program_load": "str: Program load failed"}, "n_tool_calls": 0}
{"file_name": "balance_parentheses", "model": "openai/gpt-4.1-2025-04-14", "run": 1, "runtime": 2.5935492515563965, "compile_time": 4.487218379974365, "hard_eval": {"test_0": true, "test_1": true}, "soft_eval": {}, "llm_judge_output": {}, "token_count": {"input_tokens": 1088, "output_tokens": 174, "cached_token_reads": 1024, "cached_token_writes": 0, "total_tokens": 1262}, "errors": {"test_0": null, "test_1": null}, "n_tool_calls": 0}
{"file_name": "fact_checking", "model": "openai/gpt-4.1-2025-04-14", "run": 1, "runtime": 23.50161576271057, "compile_time": 9.128318309783936, "hard_eval": {"test_0_fact_0": false, "test_0_fact_1": false, "test_0_fact_2": true, "test_1_fact_0": false, "test_1_fact_1": true, "test_2": false}, "soft_eval": {}, "llm_judge_output": {}, "token_count": {"input_tokens": 2421, "output_tokens": 426, "cached_token_reads": 2304, "cached_token_writes": 0, "total_tokens": 2847}, "errors": {}, "n_tool_calls": 0}
{"file_name": "balance_parentheses", "model": "openai/gpt-4.1-2025-04-14", "run": 2, "runtime": 2.699540615081787, "compile_time": 2.6872808933258057, "hard_eval": {"test_0": true, "test_1": true}, "soft_eval": {}, "llm_judge_output": {}, "token_count": {"input_tokens": 1088, "output_tokens": 58, "cached_token_reads": 1024, "cached_token_writes": 0, "total_tokens": 1146}, "errors": {"test_0": null, "test_1": null}, "n_tool_calls": 0}
{"file_name": "fact_checking", "model": "openai/gpt-4.1-2025-04-14", "run": 2, "runtime": 22.17056679725647, "compile_time": 7.932711124420166, "hard_eval": {"test_0_fact_0": false, "test_0_fact_1": false, "test_0_fact_2": true, "test_1_fact_0": false, "test_1_fact_1": true, "test_2": false}, "soft_eval": {}, "llm_judge_output": {}, "token_count": {"input_tokens": 2421, "output_tokens": 434, "cached_token_reads": 2304, "cached_token_writes": 0, "total_tokens": 2855}, "errors": {}, "n_tool_calls": 0}
{"file_name": "balance_parentheses", "model": "openai/gpt-4.1-2025-04-14", "run": 3, "runtime": 2.3834714889526367, "compile_time": 2.58017897605896, "hard_eval": {"test_0": true, "test_1": true}, "soft_eval": {}, "llm_judge_output": {}, "token_count": {"input_tokens": 1088, "output_tokens": 100, "cached_token_reads": 1024, "cached_token_writes": 0, "total_tokens": 1188}, "errors": {"test_0": null, "test_1": null}, "n_tool_calls": 0}
{"file_name": "fact_checking", "model": "openai/gpt-4.1-2025-04-14", "run": 3, "runtime": 12.61413836479187, "compile_time": 23.722922563552856, "hard_eval": {"test_0_fact_0": false, "test_0_fact_1": false, "test_0_fact_2": true, "test_1_fact_0": false, "test_1_fact_1": true, "test_2": false}, "soft_eval": {}, "llm_judge_output": {}, "token_count": {"input_tokens": 2421, "output_tokens": 440, "cached_token_reads": 1152, "cached_token_writes": 0, "total_tokens": 2861}, "errors": {"test_2": "UnboundLocalError: cannot access local variable 'fact' where it is not associated with a value"}, "n_tool_calls": 0}
{"file_name": "balance_parentheses", "model": "openai/gpt-4.1-2025-04-14", "run": 4, "runtime": 2.405195474624634, "compile_time": 3.674494504928589, "hard_eval": {"test_0": true, "test_1": true}, "soft_eval": {}, "llm_judge_output": {}, "token_count": {"input_tokens": 1088, "output_tokens": 107, "cached_token_reads": 0, "cached_token_writes": 0, "total_tokens": 1195}, "errors": {"test_0": null, "test_1": null}, "n_tool_calls": 0}
{"file_name": "fact_checking", "model": "openai/gpt-4.1-2025-04-14", "run": 4, "runtime": 26.747801780700684, "compile_time": 10.110628128051758, "hard_eval": {"test_0_fact_0": false, "test_0_fact_1": false, "test_0_fact_2": true, "test_1_fact_0": false, "test_1_fact_1": true, "test_2": false}, "soft_eval": {}, "llm_judge_output": {}, "token_count": {"input_tokens": 2421, "output_tokens": 471, "cached_token_reads": 2304, "cached_token_writes": 0, "total_tokens": 2892}, "errors": {}, "n_tool_calls": 0}
{"file_name": "tiny_bookshop", "model": "openai/gpt-4.1-2025-04-14", "run": 4, "runtime": 5.626678466796875e-05, "compile_time": 4.333735227584839, "hard_eval": {"test_0": false, "test_1": false, "test_2": true}, "soft_eval": {}, "llm_judge_output": {}, "token_count": {"input_tokens": 1169, "output_tokens": 71, "cached_token_reads": 0, "cached_token_writes": 0, "total_tokens": 1240}, "errors": {"test_0": "AttributeError: 'NoneType' object has no attribute 'title'"}, "n_tool_calls": 0}
{"file_name": "battle", "model": "openai/gpt-4.1-2025-04-14", "run": 0, "runtime": 4.2438507080078125e-05, "compile_time": 7.063434362411499, "hard_eval": {"test_0": false, "test_1": true, "test_2": true}, "soft_eval": {}, "llm_judge_output": {}, "token_count": {"input_tokens": 1305, "output_tokens": 256, "cached_token_reads": 0, "cached_token_writes": 0, "total_tokens": 1561}, "errors": {}, "n_tool_calls": 0}
{"file_name": "filter_numbers", "model": "openai/gpt-4.1-2025-04-14", "run": 0, "runtime": 0.0001456737518310547, "compile_time": 2.951004981994629, "hard_eval": {"test_0": false, "test_1": false, "test_2": false}, "soft_eval": {}, "llm_judge_output": {}, "token_count": {"input_tokens": 1096, "output_tokens": 30, "cached_token_reads": 0, "cached_token_writes": 0, "total_tokens": 1126}, "errors": {"test_0": "SyntaxError: invalid syntax (<string>, line 1)", "test_1": "SyntaxError: invalid syntax (<string>, line 1)", "test_2": "SyntaxError: invalid syntax (<string>, line 1)"}, "n_tool_calls": 0}
{"file_name": "gsm8k", "model": "openai/gpt-4.1-2025-04-14", "run": 0, "runtime": 0.0001418590545654297, "compile_time": 1.8093137741088867, "hard_eval": {"test_0": false, "test_1": false, "test_2": false}, "soft_eval": {}, "llm_judge_output": {}, "token_count": {"input_tokens": 1065, "output_tokens": 15, "cached_token_reads": 0, "cached_token_writes": 0, "total_tokens": 1080}, "errors": {"test_0": "SyntaxError: invalid character '\u2019' (U+2019) (<string>, line 1)", "test_1": "SyntaxError: invalid syntax (<string>, line 1)", "test_2": "SyntaxError: invalid syntax (<string>, line 1)"}, "n_tool_calls": 0}
{"file_name": "menu", "model": "openai/gpt-4.1-2025-04-14", "run": 0, "runtime": 2.9325485229492188e-05, "compile_time": 1.5828125476837158, "hard_eval": {"test_sushi": false, "test_ramen": false, "test_sashimi": false, "test_salad": false}, "soft_eval": {}, "llm_judge_output": {}, "token_count": {"input_tokens": 1087, "output_tokens": 40, "cached_token_reads": 0, "cached_token_writes": 0, "total_tokens": 1127}, "errors": {"test_0": "ValueError: not enough values to unpack (expected 2, got 1)"}, "n_tool_calls": 0}
{"file_name": "stream_generator", "model": "openai/gpt-4.1-2025-04-14", "run": 0, "runtime": null, "compile_time": null, "hard_eval": {}, "soft_eval": {}, "llm_judge_output": {}, "token_count": null, "errors": {"compilation": "str: Compilation failed"}, "n_tool_calls": 0}
{"file_name": "tiny_bookshop", "model": "openai/gpt-4.1-2025-04-14", "run": 0, "runtime": 3.4332275390625e-05, "compile_time": 1.7189946174621582, "hard_eval": {"test_0": false, "test_1": false, "test_2": true}, "soft_eval": {}, "llm_judge_output": {}, "token_count": {"input_tokens": 1169, "output_tokens": 62, "cached_token_reads": 0, "cached_token_writes": 0, "total_tokens": 1231}, "errors": {"test_0": "AttributeError: 'NoneType' object has no attribute 'title'"}, "n_tool_calls": 0}
{"file_name": "battle", "model": "openai/gpt-4.1-2025-04-14", "run": 1, "runtime": 3.0279159545898438e-05, "compile_time": 5.771443605422974, "hard_eval": {"test_0": false, "test_1": true, "test_2": true}, "soft_eval": {}, "llm_judge_output": {}, "token_count": {"input_tokens": 1305, "output_tokens": 317, "cached_token_reads": 1024, "cached_token_writes": 0, "total_tokens": 1622}, "errors": {}, "n_tool_calls": 0}
{"file_name": "filter_numbers", "model": "openai/gpt-4.1-2025-04-14", "run": 1, "runtime": null, "compile_time": 2.032703399658203, "hard_eval": {}, "soft_eval": {}, "llm_judge_output": {}, "token_count": {"input_tokens": 1096, "output_tokens": 53, "cached_token_reads": 1024, "cached_token_writes": 0, "total_tokens": 1149}, "errors": {"program_load": "str: Program load failed"}, "n_tool_calls": 0}
{"file_name": "gsm8k", "model": "openai/gpt-4.1-2025-04-14", "run": 1, "runtime": 9.1552734375e-05, "compile_time": 1.3539185523986816, "hard_eval": {"test_0": false, "test_1": false, "test_2": false}, "soft_eval": {}, "llm_judge_output": {}, "token_count": {"input_tokens": 1065, "output_tokens": 15, "cached_token_reads": 1024, "cached_token_writes": 0, "total_tokens": 1080}, "errors": {"test_0": "SyntaxError: invalid character '\u2019' (U+2019) (<string>, line 1)", "test_1": "SyntaxError: invalid syntax (<string>, line 1)", "test_2": "SyntaxError: invalid syntax (<string>, line 1)"}, "n_tool_calls": 0}
{"file_name": "menu", "model": "openai/gpt-4.1-2025-04-14", "run": 1, "runtime": 2.6941299438476562e-05, "compile_time": 1.751204252243042, "hard_eval": {"test_sushi": false, "test_ramen": false, "test_sashimi": false, "test_salad": false}, "soft_eval": {}, "llm_judge_output": {}, "token_count": {"input_tokens": 1087, "output_tokens": 43, "cached_token_reads": 1024, "cached_token_writes": 0, "total_tokens": 1130}, "errors": {"test_0": "ValueError: not enough values to unpack (expected 2, got 1)"}, "n_tool_calls": 0}
{"file_name": "stream_generator", "model": "openai/gpt-4.1-2025-04-14", "run": 1, "runtime": 4.8160552978515625e-05, "compile_time": 2.0314130783081055, "hard_eval": {"uspres_1": false, "uspres_2": false, "uspres_3": false, "p_and_p_1": false, "p_and_p_2": false, "p_and_p_3": false}, "soft_eval": {}, "llm_judge_output": {}, "token_count": {"input_tokens": 1098, "output_tokens": 66, "cached_token_reads": 1024, "cached_token_writes": 0, "total_tokens": 1164}, "errors": {}, "n_tool_calls": 0}
{"file_name": "tiny_bookshop", "model": "openai/gpt-4.1-2025-04-14", "run": 1, "runtime": 5.7697296142578125e-05, "compile_time": 2.6026763916015625, "hard_eval": {"test_0": false, "test_1": false, "test_2": true}, "soft_eval": {}, "llm_judge_output": {}, "token_count": {"input_tokens": 1169, "output_tokens": 71, "cached_token_reads": 1152, "cached_token_writes": 0, "total_tokens": 1240}, "errors": {"test_0": "AttributeError: 'NoneType' object has no attribute 'title'"}, "n_tool_calls": 0}
{"file_name": "battle", "model": "openai/gpt-4.1-2025-04-14", "run": 2, "runtime": 7.081031799316406e-05, "compile_time": 2.935044765472412, "hard_eval": {"test_0": false, "test_1": true, "test_2": true}, "soft_eval": {}, "llm_judge_output": {}, "token_count": {"input_tokens": 1305, "output_tokens": 161, "cached_token_reads": 1024, "cached_token_writes": 0, "total_tokens": 1466}, "errors": {}, "n_tool_calls": 0}
{"file_name": "filter_numbers", "model": "openai/gpt-4.1-2025-04-14", "run": 2, "runtime": null, "compile_time": 1.847937822341919, "hard_eval": {}, "soft_eval": {}, "llm_judge_output": {}, "token_count": {"input_tokens": 1096, "output_tokens": 56, "cached_token_reads": 1024, "cached_token_writes": 0, "total_tokens": 1152}, "errors": {"program_load": "str: Program load failed"}, "n_tool_calls": 0}
{"file_name": "gsm8k", "model": "openai/gpt-4.1-2025-04-14", "run": 2, "runtime": 9.083747863769531e-05, "compile_time": 1.213465929031372, "hard_eval": {"test_0": false, "test_1": false, "test_2": false}, "soft_eval": {}, "llm_judge_output": {}, "token_count": {"input_tokens": 1065, "output_tokens": 15, "cached_token_reads": 1024, "cached_token_writes": 0, "total_tokens": 1080}, "errors": {"test_0": "SyntaxError: invalid character '\u2019' (U+2019) (<string>, line 1)", "test_1": "SyntaxError: invalid syntax (<string>, line 1)", "test_2": "SyntaxError: invalid syntax (<string>, line 1)"}, "n_tool_calls": 0}
{"file_name": "menu", "model": "openai/gpt-4.1-2025-04-14", "run": 2, "runtime": 3.075599670410156e-05, "compile_time": 1.359429121017456, "hard_eval": {"test_sushi": false, "test_ramen": false, "test_sashimi": false, "test_salad": false}, "soft_eval": {}, "llm_judge_output": {}, "token_count": {"input_tokens": 1087, "output_tokens": 42, "cached_token_reads": 1024, "cached_token_writes": 0, "total_tokens": 1129}, "errors": {"test_0": "ValueError: not enough values to unpack (expected 2, got 1)"}, "n_tool_calls": 0}
{"file_name": "tiny_bookshop", "model": "openai/gpt-4.1-2025-04-14", "run": 2, "runtime": 2.2649765014648438e-05, "compile_time": 2.059964179992676, "hard_eval": {"test_0": false, "test_1": false, "test_2": true}, "soft_eval": {}, "llm_judge_output": {}, "token_count": {"input_tokens": 1169, "output_tokens": 64, "cached_token_reads": 1152, "cached_token_writes": 0, "total_tokens": 1233}, "errors": {"test_0": "AttributeError: 'NoneType' object has no attribute 'title'"}, "n_tool_calls": 0}
{"file_name": "battle", "model": "openai/gpt-4.1-2025-04-14", "run": 3, "runtime": 4.9591064453125e-05, "compile_time": 5.9230570793151855, "hard_eval": {"test_0": false, "test_1": true, "test_2": true}, "soft_eval": {}, "llm_judge_output": {}, "token_count": {"input_tokens": 1305, "output_tokens": 270, "cached_token_reads": 1024, "cached_token_writes": 0, "total_tokens": 1575}, "errors": {}, "n_tool_calls": 0}
{"file_name": "filter_numbers", "model": "openai/gpt-4.1-2025-04-14", "run": 3, "runtime": 0.00012230873107910156, "compile_time": 1.4402556419372559, "hard_eval": {"test_0": false, "test_1": false, "test_2": false}, "soft_eval": {}, "llm_judge_output": {}, "token_count": {"input_tokens": 1096, "output_tokens": 30, "cached_token_reads": 0, "cached_token_writes": 0, "total_tokens": 1126}, "errors": {"test_0": "SyntaxError: invalid syntax (<string>, line 1)", "test_1": "SyntaxError: invalid syntax (<string>, line 1)", "test_2": "SyntaxError: invalid syntax (<string>, line 1)"}, "n_tool_calls": 0}
{"file_name": "gsm8k", "model": "openai/gpt-4.1-2025-04-14", "run": 3, "runtime": 6.151199340820312e-05, "compile_time": 1.8333423137664795, "hard_eval": {"test_0": false, "test_1": false, "test_2": false}, "soft_eval": {}, "llm_judge_output": {}, "token_count": {"input_tokens": 1065, "output_tokens": 15, "cached_token_reads": 1024, "cached_token_writes": 0, "total_tokens": 1080}, "errors": {"test_0": "SyntaxError: invalid character '\u2019' (U+2019) (<string>, line 1)", "test_1": "SyntaxError: invalid syntax (<string>, line 1)", "test_2": "SyntaxError: invalid syntax (<string>, line 1)"}, "n_tool_calls": 0}
{"file_name": "menu", "model": "openai/gpt-4.1-2025-04-14", "run": 3, "runtime": 1.621246337890625e-05, "compile_time": 1.849820852279663, "hard_eval": {"test_sushi": false, "test_ramen": false, "test_sashimi": false, "test_salad": false}, "soft_eval": {}, "llm_judge_output": {}, "token_count": {"input_tokens": 1087, "output_tokens": 53, "cached_token_reads": 0, "cached_token_writes": 0, "total_tokens": 1140}, "errors": {"test_0": "ValueError: not enough values to unpack (expected 2, got 1)"}, "n_tool_calls": 0}
{"file_name": "stream_generator", "model": "openai/gpt-4.1-2025-04-14", "run": 3, "runtime": 5.0067901611328125e-05, "compile_time": 4.142196893692017, "hard_eval": {"uspres_1": false, "uspres_2": false, "uspres_3": false, "p_and_p_1": false, "p_and_p_2": false, "p_and_p_3": false}, "soft_eval": {}, "llm_judge_output": {}, "token_count": {"input_tokens": 1098, "output_tokens": 110, "cached_token_reads": 1024, "cached_token_writes": 0, "total_tokens": 1208}, "errors": {}, "n_tool_calls": 0}
{"file_name": "tiny_bookshop", "model": "openai/gpt-4.1-2025-04-14", "run": 3, "runtime": 3.123283386230469e-05, "compile_time": 2.7277681827545166, "hard_eval": {"test_0": false, "test_1": false, "test_2": true}, "soft_eval": {}, "llm_judge_output": {}, "token_count": {"input_tokens": 1169, "output_tokens": 71, "cached_token_reads": 1152, "cached_token_writes": 0, "total_tokens": 1240}, "errors": {"test_0": "AttributeError: 'NoneType' object has no attribute 'title'"}, "n_tool_calls": 0}
{"file_name": "battle", "model": "openai/gpt-4.1-2025-04-14", "run": 4, "runtime": 4.291534423828125e-05, "compile_time": 6.281860113143921, "hard_eval": {"test_0": false, "test_1": true, "test_2": true}, "soft_eval": {}, "llm_judge_output": {}, "token_count": {"input_tokens": 1305, "output_tokens": 300, "cached_token_reads": 1024, "cached_token_writes": 0, "total_tokens": 1605}, "errors": {}, "n_tool_calls": 0}
{"file_name": "filter_numbers", "model": "openai/gpt-4.1-2025-04-14", "run": 4, "runtime": null, "compile_time": 3.0064048767089844, "hard_eval": {}, "soft_eval": {}, "llm_judge_output": {}, "token_count": {"input_tokens": 1096, "output_tokens": 57, "cached_token_reads": 1024, "cached_token_writes": 0, "total_tokens": 1153}, "errors": {"program_load": "str: Program load failed"}, "n_tool_calls": 0}
{"file_name": "gsm8k", "model": "openai/gpt-4.1-2025-04-14", "run": 4, "runtime": 7.653236389160156e-05, "compile_time": 1.5306711196899414, "hard_eval": {"test_0": false, "test_1": false, "test_2": false}, "soft_eval": {}, "llm_judge_output": {}, "token_count": {"input_tokens": 1065, "output_tokens": 15, "cached_token_reads": 1024, "cached_token_writes": 0, "total_tokens": 1080}, "errors": {"test_0": "SyntaxError: invalid character '\u2019' (U+2019) (<string>, line 1)", "test_1": "SyntaxError: invalid syntax (<string>, line 1)", "test_2": "SyntaxError: invalid syntax (<string>, line 1)"}, "n_tool_calls": 0}
{"file_name": "menu", "model": "openai/gpt-4.1-2025-04-14", "run": 4, "runtime": 1.9550323486328125e-05, "compile_time": 3.510352373123169, "hard_eval": {"test_sushi": false, "test_ramen": false, "test_sashimi": false, "test_salad": false}, "soft_eval": {}, "llm_judge_output": {}, "token_count": {"input_tokens": 1087, "output_tokens": 56, "cached_token_reads": 1024, "cached_token_writes": 0, "total_tokens": 1143}, "errors": {"test_0": "ValueError: not enough values to unpack (expected 2, got 1)"}, "n_tool_calls": 0}
{"file_name": "stream_generator", "model": "openai/gpt-4.1-2025-04-14", "run": 4, "runtime": null, "compile_time": null, "hard_eval": {}, "soft_eval": {}, "llm_judge_output": {}, "token_count": null, "errors": {"compilation": "str: Compilation failed"}, "n_tool_calls": 0}
